{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning SSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we delve into the challenges of semi-supervised learning (SSL) and its application to address label scarcity in classification tasks. The dataset used in this project, the Magic Mushrooms dataset, contains features related to mushroom characteristics, previously explored in assignments 1 and 2.\n",
    "\n",
    "The primary objective is to investigate how semi-supervised learning can leverage a small amount of labeled data alongside a larger portion of unlabeled data to improve classification performance. We begin by building a supervised learning baseline using the Gradient Boosting algorithm. This serves as a benchmark against which the performance of various semi-supervised algorithms will be compared.\n",
    "\n",
    "To start the virtual enviornment, run \"source py-env/bin/activate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Fetch dataset\n",
    "drug_consumption_quantified = fetch_ucirepo(id=373)\n",
    "\n",
    "# Data as pandas DataFrames\n",
    "X = drug_consumption_quantified.data.features\n",
    "y = drug_consumption_quantified.data.targets\n",
    "\n",
    "# Convert features and targets into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "user_data = df.iloc[:, 0:12]\n",
    "\n",
    "\n",
    "choco = df['choc']\n",
    "shrooms = df['mushrooms']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the multiple classifications and convert it into binary\n",
    "mushrooms_binary = []\n",
    "\n",
    "for i in shrooms:\n",
    "    if i == 'CL0' or i == 'CL1':\n",
    "        mushrooms_binary.append(0)\n",
    "    else:\n",
    "        mushrooms_binary.append(1)\n",
    "\n",
    "mushrooms_binary = np.array(mushrooms_binary)\n",
    "\n",
    "X_mushroom_train, X_mushroom_test, y_mushroom_train, y_mushroom_test = train_test_split(user_data, mushrooms_binary, test_size=0.33, random_state=42, stratify=mushrooms_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1262, 12)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mushroom_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model eval function\n",
    "def evaluate_model(type, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model.__class__.__name__} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    disp.plot(ax=ax)\n",
    "    ax.set_title(f\"{type} Confusion Matrix for {model.__class__.__name__}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Baseline\n",
    "- Implementing the Gradient Boosting model\n",
    "- Hyperparameter optimization (Bayesian Search via Optuna)\n",
    "- Performance metrics (accuracy, precision, recall, F1-score, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 16:31:27,912] A new study created in memory with name: no-name-6ba806be-fc24-4e92-80d1-5762f71948d1\n",
      "[I 2024-12-02 16:31:28,207] Trial 0 finished with value: 0.7718112805069326 and parameters: {'n_estimators': 74, 'learning_rate': 0.241066773774347, 'max_depth': 2}. Best is trial 0 with value: 0.7718112805069326.\n",
      "[I 2024-12-02 16:31:28,480] Trial 1 finished with value: 0.7670713344626388 and parameters: {'n_estimators': 103, 'learning_rate': 0.010137597959908116, 'max_depth': 1}. Best is trial 0 with value: 0.7718112805069326.\n",
      "[I 2024-12-02 16:31:28,850] Trial 2 finished with value: 0.7805320283581152 and parameters: {'n_estimators': 163, 'learning_rate': 0.018558325172528534, 'max_depth': 1}. Best is trial 2 with value: 0.7805320283581152.\n",
      "[I 2024-12-02 16:31:29,447] Trial 3 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 117, 'learning_rate': 0.03565800263964424, 'max_depth': 3}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:29,693] Trial 4 finished with value: 0.7749858836815358 and parameters: {'n_estimators': 109, 'learning_rate': 0.01982543364230371, 'max_depth': 1}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:30,181] Trial 5 finished with value: 0.7654777589560198 and parameters: {'n_estimators': 72, 'learning_rate': 0.19740469180702344, 'max_depth': 4}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:31,382] Trial 6 finished with value: 0.7781667607754563 and parameters: {'n_estimators': 176, 'learning_rate': 0.02973301275953032, 'max_depth': 4}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:31,885] Trial 7 finished with value: 0.7813225421921073 and parameters: {'n_estimators': 139, 'learning_rate': 0.09034306307413272, 'max_depth': 2}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:32,456] Trial 8 finished with value: 0.7456804065499718 and parameters: {'n_estimators': 84, 'learning_rate': 0.3488181352897094, 'max_depth': 4}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:33,052] Trial 9 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 172, 'learning_rate': 0.09233159348391862, 'max_depth': 2}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:34,322] Trial 10 finished with value: 0.7734142668925278 and parameters: {'n_estimators': 137, 'learning_rate': 0.05504499282722209, 'max_depth': 5}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:35,015] Trial 11 finished with value: 0.7345661584792019 and parameters: {'n_estimators': 138, 'learning_rate': 0.9700882389910369, 'max_depth': 3}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:35,989] Trial 12 finished with value: 0.7773605621431707 and parameters: {'n_estimators': 197, 'learning_rate': 0.05547904783327779, 'max_depth': 3}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:36,401] Trial 13 finished with value: 0.7765543635108851 and parameters: {'n_estimators': 117, 'learning_rate': 0.1062360972743606, 'max_depth': 2}. Best is trial 3 with value: 0.7813288161114247.\n",
      "[I 2024-12-02 16:31:36,665] Trial 14 finished with value: 0.7852845222410438 and parameters: {'n_estimators': 51, 'learning_rate': 0.049952761052966164, 'max_depth': 3}. Best is trial 14 with value: 0.7852845222410438.\n",
      "[I 2024-12-02 16:31:36,982] Trial 15 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 62, 'learning_rate': 0.03686448516966779, 'max_depth': 3}. Best is trial 15 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 16:31:37,458] Trial 16 finished with value: 0.7765731852688373 and parameters: {'n_estimators': 52, 'learning_rate': 0.04930603219832809, 'max_depth': 5}. Best is trial 15 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 16:31:37,812] Trial 17 finished with value: 0.7758077671121149 and parameters: {'n_estimators': 51, 'learning_rate': 0.011867375302308818, 'max_depth': 4}. Best is trial 15 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 16:31:38,258] Trial 18 finished with value: 0.790833803877282 and parameters: {'n_estimators': 88, 'learning_rate': 0.02341417272413518, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:38,746] Trial 19 finished with value: 0.790833803877282 and parameters: {'n_estimators': 90, 'learning_rate': 0.018078198894245494, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:39,372] Trial 20 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 92, 'learning_rate': 0.016844610799964653, 'max_depth': 4}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:39,992] Trial 21 finished with value: 0.7884685362946232 and parameters: {'n_estimators': 91, 'learning_rate': 0.017115997471774464, 'max_depth': 4}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:40,863] Trial 22 finished with value: 0.7781542129368215 and parameters: {'n_estimators': 97, 'learning_rate': 0.026941438367338394, 'max_depth': 5}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:41,289] Trial 23 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 84, 'learning_rate': 0.013673980521247513, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:41,823] Trial 24 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 78, 'learning_rate': 0.022716971543133683, 'max_depth': 4}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:42,163] Trial 25 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 94, 'learning_rate': 0.014738418340191238, 'max_depth': 2}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:42,616] Trial 26 finished with value: 0.7884653993349644 and parameters: {'n_estimators': 66, 'learning_rate': 0.02453146464587253, 'max_depth': 4}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:43,224] Trial 27 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 121, 'learning_rate': 0.010924327764596077, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:43,845] Trial 28 finished with value: 0.7900401530836312 and parameters: {'n_estimators': 124, 'learning_rate': 0.01085774442920635, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:44,375] Trial 29 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 150, 'learning_rate': 0.010016510162650953, 'max_depth': 2}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:44,892] Trial 30 finished with value: 0.7678681222159482 and parameters: {'n_estimators': 104, 'learning_rate': 0.16734381663123274, 'max_depth': 3}. Best is trial 18 with value: 0.790833803877282.\n",
      "[I 2024-12-02 16:31:45,519] Trial 31 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 125, 'learning_rate': 0.01320744206815179, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:46,066] Trial 32 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 109, 'learning_rate': 0.014198476373587225, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:46,463] Trial 33 finished with value: 0.7876748855009724 and parameters: {'n_estimators': 111, 'learning_rate': 0.036399605559882135, 'max_depth': 2}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:47,119] Trial 34 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 131, 'learning_rate': 0.015064718952444694, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:47,355] Trial 35 finished with value: 0.7734048560135516 and parameters: {'n_estimators': 103, 'learning_rate': 0.02122013479430891, 'max_depth': 1}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:48,112] Trial 36 finished with value: 0.7836940836940837 and parameters: {'n_estimators': 152, 'learning_rate': 0.019141740214145796, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:48,673] Trial 37 finished with value: 0.7836972206537423 and parameters: {'n_estimators': 112, 'learning_rate': 0.032695506776608735, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:49,072] Trial 38 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 78, 'learning_rate': 0.012968011558078592, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:49,431] Trial 39 finished with value: 0.7630999435347261 and parameters: {'n_estimators': 101, 'learning_rate': 0.34143615914108116, 'max_depth': 2}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:49,632] Trial 40 finished with value: 0.7789478637304723 and parameters: {'n_estimators': 86, 'learning_rate': 0.04128667703477681, 'max_depth': 1}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:50,275] Trial 41 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 128, 'learning_rate': 0.010166482000124941, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:50,893] Trial 42 finished with value: 0.788459125415647 and parameters: {'n_estimators': 123, 'learning_rate': 0.018475863342662224, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:51,628] Trial 43 finished with value: 0.7836972206537423 and parameters: {'n_estimators': 148, 'learning_rate': 0.0274201857341979, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:52,206] Trial 44 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 115, 'learning_rate': 0.013860822882404462, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:52,935] Trial 45 finished with value: 0.7749921576008532 and parameters: {'n_estimators': 109, 'learning_rate': 0.07503200920471984, 'max_depth': 4}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:53,407] Trial 46 finished with value: 0.7884622623753058 and parameters: {'n_estimators': 133, 'learning_rate': 0.013961210749492458, 'max_depth': 2}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:54,188] Trial 47 finished with value: 0.7845034192860278 and parameters: {'n_estimators': 116, 'learning_rate': 0.024270732801959044, 'max_depth': 4}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:54,547] Trial 48 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 70, 'learning_rate': 0.020690725100406638, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 16:31:54,894] Trial 49 finished with value: 0.7852845222410438 and parameters: {'n_estimators': 68, 'learning_rate': 0.06826963343628291, 'max_depth': 3}. Best is trial 31 with value: 0.7932147562582343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 125, 'learning_rate': 0.01320744206815179, 'max_depth': 3}\n",
      "Best cross-validation accuracy: 0.7932147562582343\n",
      "GradientBoostingClassifier - Accuracy: 0.7431781701444623, Precision: 0.6589861751152074, Recall: 0.6244541484716157\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAHHCAYAAAA4drvmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSi0lEQVR4nO3deVwU9f8H8Ndy7HKDKIcoIHgheRWakncSiOaRmlpWeJtn3kflWcYvzTLvzAM1ydLSktLC25Q07yM8ULwFVFQE5dr9/P7wy+Ry7s4CI/J6Ph7zeLAzn5l5szu7+97PNSohhAARERGRgcyUDoCIiIjKFiYPREREZBQmD0RERGQUJg9ERERkFCYPREREZBQmD0RERGQUJg9ERERkFCYPREREZBQmD0RERGSUMpk8VKtWDa+//rrSYZQL2dnZmDBhAjw9PWFmZoYuXboU+zlat26N1q1bF/txy6qIiAioVCpcvny52I65du1a+Pn5wdLSEk5OTsV23LIg9/V1+fJlqFQqREREKBZTWVUS16apdu/eDZVKhd27dysWg0qlwvTp0/XW/fPPP3jllVdga2sLlUqF48ePY/r06VCpVMoEWcyMSh5yLhyVSoW//vorz3YhBDw9PaFSqfjlXozS09Px1VdfoUmTJnB0dISVlRVq1aqF4cOH4/z58yV67pUrV2LOnDno3r07Vq9ejdGjR5fo+UpTzoeOSqXCd999l2+ZZs2aQaVSoW7durLOsXjxYsW/pM6ePYs+ffqgevXq+Pbbb7Fs2bJSOe/JkyfRt29f+Pj4wMrKCnZ2dmjYsCEmTJiAS5culUoMSirotX/6ustZnJ2d0bRpU6xbt670A83HZ599hs2bNysdBjZt2oTQ0FBUqlQJarUaHh4e6NGjB3bu3Kl0aIXKysrCm2++ieTkZHz11VdYu3YtvL29lQ6reAkjrFq1SgAQVlZWYsiQIXm279q1SwAQGo1GdOjQwZhDG8Xb27tEj/8suX37tggICBAAxOuvvy7mzZsnli9fLsaPHy88PT2FpaVliZ6/Z8+eokqVKiV6joyMDJGRkVGi58hPzvVqZWUlQkND82yPj4+Xtr/wwguyzvHCCy+IVq1aGbVPdna2ePz4sdDpdLLOmduSJUsEAHHhwoViOZ4hli1bJszNzYWbm5sYM2aMWLZsmVi8eLEYOnSocHNzE5aWliI7O7tUYmnVqpXea6DT6cTjx49L/PwFvfY5193IkSPF2rVrxdq1a8W8efNEYGCgACAWLlxYonEZwtbWVoSFheVZX9zXZkF0Op3o06ePACBefPFFMWvWLLFixQrx6aefSp+H+/fvF0L893zu2rWrRGMqzOPHj0VWVpb0ODY2VgAQ3377rV65rKws8fjx49IOr0RYyEk42rdvjw0bNmD+/PmwsPjvEJGRkQgICMCdO3dMSmhKUlpaGmxtbZUOw2B9+vTBsWPHsHHjRnTr1k1v2yeffIKPPvqoRM+flJRU4tXcarW6RI9flPbt2+PXX3/FnTt3UKlSJWl9ZGQk3NzcULNmTdy7d6/E48i5Ns3NzWFubl5sx01KSgKAYn0dHz16BBsbm3y3HThwAEOGDEGzZs0QFRUFe3t7ve1z587FrFmzTDqHKVQqFaysrIr9uMZq0aIFunfvLj0eMmQIfH19ERkZiWHDhikYWcGK+9osyNy5cxEREYFRo0bhyy+/1Kvq/+ijj7B27Vq97x6l5b6eCnrPWVhYFGvcJfUeMYgxmUZOzcOGDRuESqUSv//+u7QtIyNDVKhQQcydOzdPzUBBmWHOL7tVq1ZJ627duiX69OkjqlSpItRqtXB3dxedOnUS8fHxUpmc4+/bt080btxYaDQa4ePjI1avXp1vvLt37xZDhgwRLi4uwsnJSdq+aNEi4e/vL9RqtahcubIYOnSouHfvXp7/+8cffxQvvfSSsLKyEhUrVhS9e/cW169f1ysTFhYmbG1txZUrV0SHDh2Era2t8PDwkH5FnDx5UrRp00bY2NgILy8vsW7duiKf77///lsAEAMHDiyybI4dO3aI5s2bCxsbG+Ho6Cg6deok/v33X70y06ZNk36JhoWFCUdHR+Hg4CD69Okj0tLShBD/vTa5l127dhX765n7l6EQQiQmJop+/foJV1dXodFoRP369UVERES+55szZ4745ptvhK+vr1Cr1aJRo0bi0KFDRT5XOf/H6tWrha2trVi8eLHe9hdeeEGMGDFCtGrVKk/Nw8qVK0WbNm2Ei4uLUKvVok6dOnn29/b2zvP85fyfhV2bOdtynqMdO3YIlUolpkyZonf8devWCQB5zltUDNOmTZO2G/IeyPn/Dx8+LFq0aCGsra3FBx98UOA5g4ODhYWFhbh27VqBZXIr7BybN28W7du3F5UrVxZqtVr4+vqKmTNn5ltzkHMdWFlZicaNG4u9e/fmub7yu06FePJrsVu3bqJChQpCo9GIgIAA8csvv+iVyXlt/vrrLzF69GhRqVIlYWNjI7p06SKSkpKkcoW99jnX3YYNG/LEX7duXdGyZUu9dVlZWWLmzJnS9e3t7S0mT54s0tPT8+xvyOt5/vx50bVrV+Hm5iY0Go2oUqWK6Nmzp7h//74QQuT7vs+phch9beb8r4Z8HgshxIkTJ0TLli2FlZWVqFKlivjkk0/EypUr9Y756NEj4ezsLPz8/AyqHcrv82jv3r2ie/fuwtPTU6jValG1alUxatQo8ejRI719Dfl8+ueff0RwcLCoWLGisLKyEtWqVRN9+/bVO87T76uwsLACX/ucz97c1q5dK33HVKhQQfTs2VNcvXpVr4yx78OSJisFqlatGgIDA/H9998jNDQUALB161Y8ePAAvXr1wvz58+UcFgDQrVs3nDlzBiNGjEC1atWQlJSE6OhoXL16FdWqVZPKxcXFoXv37ujfvz/CwsKwcuVK9OnTBwEBAXjhhRf0jjl06FC4uLhg6tSpSEtLAwBMnz4dM2bMQFBQEIYMGYJz585hyZIl+Oeff7B//35YWloCeNLPo2/fvmjcuDHCw8ORmJiIr7/+Gvv378exY8f0MkutVovQ0FC0bNkSs2fPxrp16zB8+HDY2trio48+Qu/evdG1a1csXboU7733HgIDA+Hj41Pgc/Hrr78CAN59912Dnrvt27cjNDQUvr6+mD59Oh4/fowFCxagWbNmOHr0qN7zBwA9evSAj48PwsPDcfToUSxfvhyurq74/PPP4eLigrVr12LWrFlITU1FeHg4AKBOnTqIjY01KB7A8NfzaY8fP0br1q0RFxeH4cOHw8fHBxs2bECfPn1w//59fPDBB3rlIyMj8fDhQwwePBgqlQqzZ89G165dcenSJel1LIyNjQ06d+6M77//HkOGDAEAnDhxAmfOnMHy5ctx8uTJPPssWbIEL7zwAjp16gQLCwts2bIFQ4cOhU6nk341zps3DyNGjICdnZ1UQ+Tm5qZ3nPyuzdxeffVVDB06FOHh4ejSpQteeukl3Lp1CyNGjEBQUBDef//9Av+3efPmYc2aNdi0aROWLFkCOzs71K9fH4Dh7wEAuHv3LkJDQ9GrVy+88847ef6PHI8ePcLOnTvRunVrVK1atcC48lPQOSIiImBnZ4cxY8bAzs4OO3fuxNSpU5GSkoI5c+ZI+69YsQKDBw/GK6+8glGjRuHSpUvo1KkTnJ2d4enpWei5z5w5g2bNmqFKlSqYNGkSbG1t8eOPP6JLly746aef8MYbb+iVHzFiBCpUqIBp06bh8uXLmDdvHoYPH44ffvhBet6Leu0fPnwo1dImJycjMjISp0+fxooVK/TKDRgwAKtXr0b37t0xduxYHDx4EOHh4YiNjcWmTZukcoa8npmZmQgJCUFGRgZGjBgBd3d33LhxA1FRUbh//z4cHR2xdu1aDBgwAC+//DIGDRoEAKhevXqhz58hn8c3btxAmzZtoFKpMHnyZNja2mL58uXQaDR6x/rrr7+QnJyMUaNGya7l2LBhAx49eoQhQ4agYsWKOHToEBYsWIDr169jw4YNUrmiPp+SkpIQHBwMFxcXTJo0CU5OTrh8+TJ+/vnnAs89ePBgVKlSBZ999hlGjhyJxo0bF/h+AYBZs2ZhypQp6NGjBwYMGIDbt29jwYIFaNmyZZ7vGEPfh6XCmEwjJ+v8559/xMKFC4W9vb2Uyb355puiTZs2Qoi8fRIM/aV679496ZdkYXKy+r1790rrkpKShEajEWPHjs0Tb/PmzfUy2KSkJKFWq0VwcLDQarXS+oULFwoAYuXKlUIIITIzM4Wrq6uoW7euXjtVVFSUACCmTp0qrcvJNj/77DNp3b1794S1tbVQqVRi/fr10vqzZ8/m+QWYnzfeeEMAyLc2JD8NGzYUrq6u4u7du9K6EydOCDMzM/Hee+9J63Ky3379+uU5X8WKFfXW5feru7hfz9y/DOfNmycAiO+++05al5mZKQIDA4WdnZ1ISUnRO1/FihVFcnKyVPaXX34RAMSWLVsKPe/TvwCjoqKESqWSsv3x48cLX1/fAp+D3L9ghBAiJCRE2idHQe3eBV2bT297+tdPWlqaqFGjhnjhhRdEenq66NChg3BwcBBXrlwp9H8U4r/X+/bt29I6Q98DOf8/ALF06dIiz3XixAkBQIwaNSrPtrt374rbt29Ly9P9XAo7R37P9eDBg4WNjY306zvnvdqwYUO94y5btkzvl58Q+dc8tG3bVtSrV0/v17xOpxOvvPKKqFmzprQu57UJCgrSa/cfPXq0MDc3l369C1F0n4fci5mZmZg1a5Ze2ePHjwsAYsCAAXrrx40bJwCInTt3CiEMfz2PHTtWYK3H0wrq81BQzYMhn8cjRowQKpVKHDt2TFp39+5d4ezsrHfMr7/+WgAQmzZtKjTGHPl9HuV3zYSHhwuVSiW9Zwz5fNq0aZP0nVeY3J/nBdUu5a55uHz5sjA3N8/zup86dUpYWFjorTfmfVgaZA/V7NGjBx4/foyoqCg8fPgQUVFRePvtt+UeDgBgbW0NtVqN3bt3F9nG7O/vjxYtWkiPXVxcULt27Xx7cQ8cOFAvg92+fTsyMzMxatQomJmZ6ZVzcHDAb7/9BgA4fPgwkpKSMHToUL02rQ4dOsDPz08q97QBAwZIfzs5OaF27dqwtbVFjx49pPW1a9eGk5NTkT3OU1JSACBPm3F+bt26hePHj6NPnz5wdnaW1tevXx+vvfYafv/99zz75P7F2qJFC9y9e1c6r6mMeT2f9vvvv8Pd3R1vvfWWtM7S0hIjR45Eamoq9uzZo1e+Z8+eqFChgvQ457owpkd/cHAwnJ2dsX79egghsH79er3z52ZtbS39/eDBA9y5cwetWrXCpUuX8ODBA4PPm/vaLIiNjQ0iIiIQGxuLli1b4rfffsNXX30FLy8vg8/1NEPfAzk0Gg369u1b5HFzrh07O7s823x9feHi4iItOTVrRZ3j6ec659d6ixYt8OjRI5w9exbAf+/V999/X68PTZ8+feDo6FhozMnJydi5cyd69OghHf/OnTu4e/cuQkJCcOHCBdy4cUNvn0GDBum1w7do0QJarRZXrlwp9FxPmzp1KqKjoxEdHY0ffvgBb731Fj766CN8/fXXUpmc9+2YMWP09h07diwASK+Toa9nznPxxx9/4NGjRwbHWhRDPo+3bduGwMBANGzYUFrn7OyM3r176x3LmM+9gjx9zaSlpeHOnTt45ZVXIITAsWPHpDJFfT7l/OqPiopCVlaW7HgK8vPPP0On06FHjx7SdXfnzh24u7ujZs2a2LVrl155Q9+HpUF28uDi4oKgoCBERkbi559/hlar1ev8I4dGo8Hnn3+OrVu3ws3NTar+T0hIyFM2vw/NChUq5HsR5G4ayHmD165dW2+9Wq2Gr6+vtL2gcgDg5+eX54PCysoKLi4ueuscHR1RtWrVPGN7HR0di/xCdXBwAPDkA7MohcVap04d3LlzJ0+1eO7nMOcLuLg6Bxrzej7typUrqFmzpt6HIPDk/8jZ/rTi+D8sLS3x5ptvIjIyEnv37sW1a9cKTYb379+PoKAg2NrawsnJCS4uLvjwww8BwKjkobBmq9yaNWuGIUOG4NChQwgJCUG/fv0M3jc3Q98DOapUqWJQx9acD/zU1NQ823755RdER0fjiy++yHffgs5x5swZvPHGG3B0dISDgwNcXFzwzjvvAPjvuc6Jt2bNmnr7WlpawtfXt9CY4+LiIITAlClT9JIbFxcXTJs2DcB/HeByFMc1V69ePQQFBSEoKAg9evTAd999h9dffx2TJk3C7du3pf/LzMwMNWrU0NvX3d0dTk5ORX5W5X49fXx8MGbMGCxfvhyVKlVCSEgIFi1aZNQ1mx9DPo+vXLmS5/8AkGedMZ97Bbl69ar0Q8rOzg4uLi5o1aoVgP+uGUM+n1q1aoVu3bphxowZqFSpEjp37oxVq1YhIyNDdmxPu3DhAoQQqFmzZp5rLzY2Ns91Z+j7sDSYNEnU22+/ja1bt2Lp0qUIDQ0tsDd3QZNiaLXaPOtGjRqF8+fPIzw8HFZWVpgyZQrq1KkjZYs5Cvq1JoTIs+7pLLQkFRSTMbE+zc/PDwBw6tQp0wIrgNy4SuL1NIXc/yO3t99+W5rIpUGDBvD398+33MWLF9G2bVvcuXMHX375JX777TdER0dLc2DodDqDz2nMtZmRkSFNhHPx4sVi/eVYFEPjrFGjBiwsLHD69Ok821q1aoWgoCAEBAQYfI779++jVatWOHHiBGbOnIktW7YgOjoan3/+OQDjnuuC5Bxj3LhxUk1A7iX3F1xxXXO5tW3bFunp6Th06JDe+uKcWGju3Lk4efIkPvzwQzx+/BgjR47ECy+8gOvXr8s+ZnE+H6Z+7mm1Wrz22mv47bffMHHiRGzevBnR0dHSnBtPXzNFfT6pVCps3LgRMTExGD58OG7cuIF+/fohICAg3wTZWDqdDiqVCtu2bcv3uvvmm2/0ypfWd5khTEoe3njjDZiZmeHvv/8u9FdaTlZ+//59vfUFVfFVr14dY8eOxZ9//onTp08jMzMTc+fONSVUPTmTdZw7d05vfWZmJuLj46XtBZXLWVfSk3507NgRAAqcwOhphcV69uxZVKpUqdiGqJb06+nt7Y0LFy7k+WLIqaIuqee9efPm8PLywu7duwu9nrds2YKMjAz8+uuvGDx4MNq3b4+goKB839jF+aE/bdo0xMbG4osvvkB8fDwmTZok+1iGvgeMZWtri9atW2PPnj15qvrl2L17N+7evYuIiAh88MEHeP311xEUFKTXTAX89/9cuHBBb31WVhbi4+MLPUdOzYSlpaVUE5B7kVOFLue1z87OBvBfzY23tzd0Ol2e/ysxMRH3798v8rOqoNezXr16+Pjjj7F3717s27cPN27cwNKlS02KvSje3t6Ii4vLsz73uubNm6NChQr4/vvv8/1BUpRTp07h/PnzmDt3LiZOnIjOnTsjKCgIHh4e+ZY35POpadOmmDVrFg4fPox169bhzJkzWL9+vdGx5XduIQR8fHzyve6aNm1q8jlKiknJg52dHZYsWYLp06dLX3T58fb2hrm5Ofbu3au3fvHixXqPHz16hPT0dL111atXh729fbFVEwFAUFAQ1Go15s+fr5cZr1ixAg8ePECHDh0AAI0aNYKrqyuWLl2qd/6tW7ciNjZWKldSAgMD0a5dOyxfvjzf2d4yMzMxbtw4AEDlypXRsGFDrF69Wu9L/fTp0/jzzz/Rvn37YourpF/P9u3bIyEhQeq5Djz5UF2wYAHs7Oyk6sfiplKpMH/+fEybNq3QES45v7KevnYePHiAVatW5Slra2ubJ8mS4+DBg/jiiy8watQojB07FuPHj8fChQvz9P8wlKHvATmmTp0KrVaLd955J99fZ8b8Gs3vuc7MzMxzrTVq1AguLi5YunQpMjMzpfURERFFPv+urq5o3bo1vvnmG9y6dSvP9pwmBGPJee2joqIAAA0aNAAA6X07b948vXJffvklAEivk6GvZ0pKipSg5KhXrx7MzMz03pPFdd0+LSQkBDExMTh+/Li0Ljk5Oc+smjY2Npg4cSJiY2MxceLEfK+X7777Lk/tTI78rhkhhF5fEsCwz6d79+7lOX9On43i+E7q2rUrzM3NMWPGjDznEULg7t27Jp+jpJg8W0VYWFiRZRwdHfHmm29iwYIFUKlUqF69OqKiovK055w/fx5t27ZFjx494O/vDwsLC2zatAmJiYno1auXqaFKXFxcMHnyZMyYMQPt2rVDp06dcO7cOSxevBiNGzeW2lMtLS3x+eefo2/fvmjVqhXeeustaahmtWrVSmWq5jVr1iA4OBhdu3ZFx44d0bZtW9ja2uLChQtYv349bt26JbUhz5kzB6GhoQgMDET//v2loZqOjo555l03RUm/noMGDcI333yDPn364MiRI6hWrRo2btyI/fv3Y968eSZ1pCpK586d0blz50LLBAcHQ61Wo2PHjhg8eDBSU1Px7bffwtXVNc+XT0BAAJYsWYJPP/0UNWrUgKurK1599VWjYkpPT0dYWBhq1qwpTa40Y8YMbNmyBX379sWpU6eMrlUy9D0gR4sWLbBw4UKMGDECNWvWRO/eveHn54fMzEycP38e69atg1qthru7e5HHeuWVV1ChQgWEhYVh5MiRUKlUWLt2bZ4PWktLS3z66acYPHgwXn31VfTs2RPx8fFYtWpVkX0eAGDRokVo3rw56tWrh4EDB8LX1xeJiYmIiYnB9evXceLECaOfh6Je+3379klfXsnJyfj111+xZ88e9OrVS6q6b9CgAcLCwrBs2TKpCefQoUNYvXo1unTpgjZt2gAw/PXcuXMnhg8fjjfffBO1atVCdnY21q5dC3Nzc71J6AICArB9+3Z8+eWX8PDwgI+PD5o0aWL0c/C0CRMm4LvvvsNrr72GESNGSEM1vby8kJycrFfbMX78eJw5cwZz587Frl270L17d7i7uyMhIQGbN2/GoUOHcODAgXzP4+fnh+rVq2PcuHG4ceMGHBwc8NNPP+Xpj2LI59Pq1auxePFivPHGG6hevToePnyIb7/9Fg4ODsXyg6x69er49NNPMXnyZFy+fBldunSBvb094uPjsWnTJgwaNEj6gfjMMWZoxtNDNQuT3/TRt2/fFt26dRM2NjaiQoUKYvDgweL06dN6Q6bu3Lkjhg0bJvz8/IStra1wdHQUTZo0ET/++GORxxci75C/ouJduHCh8PPzE5aWlsLNzU0MGTIk32GRP/zwg3jxxReFRqMRzs7OhU4SlV9M+U1tbMwU248ePRJffPGFaNy4sbCzsxNqtVrUrFlTjBgxQsTFxemV3b59u2jWrJmwtrYWDg4OomPHjgVOEvX00D0h8h+GVVD8xfl6FjRJVN++fUWlSpWEWq0W9erVyzOpz9OTROUGA4bCFjZZT+74cj8Hv/76q6hfv740acznn3+eZ7IbIYRISEgQHTp0EPb29npDBgu7NnO/DjnDAA8ePKhX7vDhw8LCwiLfqeKfVtDrLYRh74GCroGiHDt2TLz33nvCy8tLqNVqYWtrK+rXry/Gjh2b57ot7Bz79+8XTZs2FdbW1sLDw0NMmDBB/PHHH/kOF168eLHw8fERGo1GNGrUyKhJoi5evCjee+894e7uLiwtLUWVKlXE66+/LjZu3CiVKeh1y2+4YEGvfX5DNdVqtfDz8xOzZs0SmZmZesfOysoSM2bMED4+PsLS0lJ4enoWOElUUa/npUuXRL9+/UT16tWFlZWVcHZ2Fm3atBHbt2/XO87Zs2dFy5YthbW1tYCBk0Tllt/7+tixY6JFixZCo9GIqlWrivDwcDF//nwBQCQkJOQ5xsaNG0VwcLBwdnYWFhYWonLlyqJnz55i9+7dhT73//77rwgKChJ2dnaiUqVKYuDAgdIwYmM+n44ePSreeust4eXlJTQajXB1dRWvv/66OHz4sF6cuT9vDB2qmeOnn34SzZs3F7a2tsLW1lb4+fmJYcOGiXPnzuk9n3KnyS8JKiFM7OFDREQk06hRo/DNN98gNTW1VKa+puJRJm/JTUREZc/jx4/1Ht+9exdr165F8+bNmTiUMc/OnUWIiOi5FhgYiNatW6NOnTpITEzEihUrkJKSgilTpigdGhmJyQMREZWK9u3bY+PGjVi2bBlUKhVeeuklrFixAi1btlQ6NDIS+zwQERGRUdjngYiIiIzC5IGIiIiMwj4Pueh0Oty8eRP29vYlMkUrERGVHCEEHj58CA8Pjzw31ytO6enperOZyqVWq/Xu2lxWMHnI5ebNm/D09FQ6DCIiMsG1a9dQtWrVEjl2eno6fLztkJBk/L03cnN3d0d8fHyZSyCYPOSSM/XxlaPV4GDHVh16Pr1Rq57SIRCViGxk4S/8XqLT2GdmZiIhSYsrR6rBwV7+90TKQx28Ay4jMzOTyUNZl9NU4WBnZtJFQfQss1BZKh0CUcn43/jB0mh2trNXwc5e/nl0KLtN40weiIiIZNAKHbQmTHagFbriC6aUMXkgIiKSQQcBHeRnD6bsqzTWyxMREZFRWPNAREQkgw46mNLwYNreymLyQEREJINWCGhNuMODKfsqjc0WREREZBTWPBAREclQnjtMMnkgIiKSQQcBbTlNHthsQUREREZhzQMREZEMbLYgIiIio3C0BREREZGBWPNAREQkg+5/iyn7l1VMHoiIiGTQmjjawpR9lcbkgYiISAatgIl31Sy+WEob+zwQERGRUVjzQEREJAP7PBAREZFRdFBBC5VJ+5dVbLYgIiIio7DmgYiISAadeLKYsn9ZxeSBiIhIBq2JzRam7Ks0NlsQERGRUVjzQEREJANrHoiIiMgoOqEyeTHGkiVLUL9+fTg4OMDBwQGBgYHYunWrtD09PR3Dhg1DxYoVYWdnh27duiExMVHvGFevXkWHDh1gY2MDV1dXjB8/HtnZ2Ub/70weiIiIyoCqVavi//7v/3DkyBEcPnwYr776Kjp37owzZ84AAEaPHo0tW7Zgw4YN2LNnD27evImuXbtK+2u1WnTo0AGZmZk4cOAAVq9ejYiICEydOtXoWFRClOF7gpaAlJQUODo64t55XzjYM7ei51OIR0OlQyAqEdkiC7vxCx48eAAHB4cSOUfO98Se01VgZ8L3ROpDHVrVvWFSrM7OzpgzZw66d+8OFxcXREZGonv37gCAs2fPok6dOoiJiUHTpk2xdetWvP7667h58ybc3NwAAEuXLsXEiRNx+/ZtqNVqg8/Lb0ciIiIZtDAzeQGeJCNPLxkZGUWfW6vF+vXrkZaWhsDAQBw5cgRZWVkICgqSyvj5+cHLywsxMTEAgJiYGNSrV09KHAAgJCQEKSkpUu2FoZg8EBERySBM7O8g/tfnwdPTE46OjtISHh5e4DlPnToFOzs7aDQavP/++9i0aRP8/f2RkJAAtVoNJycnvfJubm5ISEgAACQkJOglDjnbc7YZg6MtiIiIFHTt2jW9ZguNRlNg2dq1a+P48eN48OABNm7ciLCwMOzZs6c0wtTD5IGIiEiG4hqqmTN6whBqtRo1atQAAAQEBOCff/7B119/jZ49eyIzMxP379/Xq31ITEyEu7s7AMDd3R2HDh3SO17OaIycMoZiswUREZEMWmFm8mIqnU6HjIwMBAQEwNLSEjt27JC2nTt3DlevXkVgYCAAIDAwEKdOnUJSUpJUJjo6Gg4ODvD39zfqvKx5ICIiKgMmT56M0NBQeHl54eHDh4iMjMTu3bvxxx9/wNHREf3798eYMWPg7OwMBwcHjBgxAoGBgWjatCkAIDg4GP7+/nj33Xcxe/ZsJCQk4OOPP8awYcMKbSrJD5MHIiIiGXRQQWdCBb4Oxs2UkJSUhPfeew+3bt2Co6Mj6tevjz/++AOvvfYaAOCrr76CmZkZunXrhoyMDISEhGDx4sXS/ubm5oiKisKQIUMQGBgIW1tbhIWFYebMmUbHznkecuE8D1QecJ4Hel6V5jwPv56sDlt7c9nHSXuoRaf6F0s01pLCb0ciIiIyCpstiIiIZDC106O2DFf8M3kgIiKS4UmfB/lDNU3ZV2lstiAiIiKjsOaBiIhIBt1T96eQtz+bLYiIiMoV9nkgIiIio+hgVqrzPDxL2OeBiIiIjMKaByIiIhm0QgWtMOHGWCbsqzQmD0RERDJoTewwqWWzBREREZUXrHkgIiKSQSfMoDNhtIWOoy2IiIjKFzZbEBERERmINQ9EREQy6GDaiAld8YVS6pg8EBERyWD6JFFlt/K/7EZOREREimDNAxERkQym39ui7P5+Z/JAREQkgw4q6GBKnwfOMElERFSulOeah7IbORERESmCNQ9EREQymD5JVNn9/c7kgYiISAadUEFnyjwPZfiummU37SEiIiJFsOaBiIhIBp2JzRZleZIoJg9EREQymH5XzbKbPJTdyImIiEgRrHkgIiKSQQsVtCZM9GTKvkpj8kBERCQDmy2IiIiIDMSaByIiIhm0MK3pQVt8oZQ6Jg9EREQylOdmCyYPREREMvDGWEREREQGYs0DERGRDAIq6Ezo8yA4VJOIiKh8YbMFERERkYFY80BERCRDeb4lN5MHIiIiGbQm3lXTlH2VVnYjJyIiIkWw5oGIiEgGNlsQERGRUXQwg86ECnxT9lVa2Y2ciIiIFMGaByIiIhm0QgWtCU0PpuyrNCYPREREMrDPAxERERlFmHhXTcEZJomIiKi8YM0DERGRDFqooDXh5lam7Ks0Jg9EREQy6IRp/RZ0ohiDKWVstiAiIiKjsOaBit2W1RXx25pKSLymBgB4105H79EJaPzqQ6TcM8faL9xxdI89km6q4eicjVfaPUDYhFuwddBJx0i6bokFk6vixH57WNlq8dqb99Dvw5sw5xVLz6DVB/+Fu2dWnvW/RlTEog+rPrVG4NPv4tH41YeY3q8aYrY5ll6QVOx0JnaYNGVfpT2XH8WLFi3CnDlzkJCQgAYNGmDBggV4+eWXlQ6r3HCpnIV+H95EFZ8MCKFC9IYKmN7XB4v+PA8I4G6iJQZOvQmvWulIuq7G/ElVcTfRElO+vQwA0GqBKe/5ooJLNr769QKSkywwZ6Q3zC0F+k2+pew/R5SPkaG1YGb+Xx10Nb90/N8Pl7Bvi5NeuTcG3oEow1XVpE8HFXQm9FswZV+lld20pwA//PADxowZg2nTpuHo0aNo0KABQkJCkJSUpHRo5UbT4BS83PYhqvhmomr1DPSdlAArWx3OHrFBNb90TF1+GU2DU+BRLRMNm6eiz8RbOBjtAG32k/2P7rHH1fNWmLjwCqrXfYzGrz7EexNuYUtEJWRllt03Gz2/HiRb4N5tS2lpEpSCm/FqnIyxlcr4vvAY3QbfxpdjPBWMlKh4PHfJw5dffomBAweib9++8Pf3x9KlS2FjY4OVK1cqHVq5pNUCuzc7IeORGeo0Ssu3TFqKOWzsdFKTxL+HbVHNLx0VXLKlMo1aP8Sjh+a4cs6qNMImks3CUodXu93DH+udgf/9stRY6zBp0RUs+qgK7t22VDZAKjY5M0yaspRVz1WzRWZmJo4cOYLJkydL68zMzBAUFISYmBgFIyt/4mOtMKpjTWRmmMHaVoepK+LhXSsjT7kHd80ROc8doe/ckdbdu22BCi767cdOlbKkbUTPslfapcDOQYs/f3SW1g2efgP/HrZFzB/s4/A8YZ+H58SdO3eg1Wrh5uamt97NzQ1nz57Nd5+MjAxkZPz3pZaSklKiMZYXVatnYHH0OTx6aI59UU744gNvzPn5gl4CkfbQDFPe84VXrXS8OzZBwWiJik/IW3fxzy4HJCc+qWFoGvwADZulYmhwLYUjIyo+ZTftKSbh4eFwdHSUFk9PtkcWB0u1QBWfTNSs/xj9PrwFH//H2LzcRdr+KNUMH71dHda2OkxbEQ+Lp2pyK7hk56navX/HUtpG9KxyrZKJF1ukYlvkf7UODZulonK1TPx89jR+v3oCv189AQCY8u1lzN4Yp1SoVAx0UEn3t5C1lOEOk89VzUOlSpVgbm6OxMREvfWJiYlwd3fPd5/JkydjzJgx0uOUlBQmECVACCAr80mumvbwSeJgqRaYEXEJaiv97uf+jdKwfr4b7t+xgFOlJ8nC0b32sLHXwqtWeqnHTmSo4F7JuH/HAge3O0jrfljoiq1PJRMAsGzXeXwz3QN//+mQ+xBUhggTR1sIJg/PBrVajYCAAOzYsQNdunQBAOh0OuzYsQPDhw/Pdx+NRgONRlOKUT7/Vn5WGY1fTYFLlSw8TjXDrk0VcPKAHWZFXkTaQzN8+FZ1ZDw2w4QF8XiUao5HqU/2c6yYDXNz4KVWD+FVKx2zR3ih/8c3ce+2JSI+d0fHPneg1nCcGz2bVCqB4J7J2L6hAnTa/74UckZg5JZ0Q43Ea/zsKct4V83nyJgxYxAWFoZGjRrh5Zdfxrx585CWloa+ffsqHVq5cf/Ok3kZkpMsYGOvhU+ddMyKvIiAVqk4ccAOZ48+Gb7W9xV/vf2eTLSTCXNzYOaaS1gwyROjO9aClY0OQW8mI2w853igZ9eLLVPhVjULf6yvqHQoRCXuuUseevbsidu3b2Pq1KlISEhAw4YNsW3btjydKKnkjPnyWoHbGrySij9uHi/yGG5Vs/Dpd5eKMSqiknV0jz1CPBoYVNbQcvRs42iL58zw4cMLbKYgIiIqDuW52aLspj1ERESkiOey5oGIiKik8d4WREREZBST5niQ0eQRHh6Oxo0bw97eHq6urujSpQvOnTunV6Z169ZQqVR6y/vvv69X5urVq+jQoQNsbGzg6uqK8ePHIzvbuDl0WPNARERUBuzZswfDhg1D48aNkZ2djQ8//BDBwcH4999/YWv7303YBg4ciJkzZ0qPbWxspL+1Wi06dOgAd3d3HDhwALdu3cJ7770HS0tLfPbZZwbHwuSBiIhIhtLuMLlt2za9xxEREXB1dcWRI0fQsmVLab2NjU2BEyP++eef+Pfff7F9+3a4ubmhYcOG+OSTTzBx4kRMnz4darXaoFjYbEFERCRDcTVbpKSk6C1P32+pMA8ePAAAODvrz2C6bt06VKpUCXXr1sXkyZPx6NEjaVtMTAzq1aunN31BSEgIUlJScObMGYP/d9Y8EBERKSj3LRGmTZuG6dOnF7qPTqfDqFGj0KxZM9StW1da//bbb8Pb2xseHh44efIkJk6ciHPnzuHnn38GACQkJOR788icbYZi8kBERCRDcTVbXLt2DQ4O/93nxJBbJgwbNgynT5/GX3/9pbd+0KBB0t/16tVD5cqV0bZtW1y8eBHVq1eXHWtubLYgIiKSQeC/4Zpylpw79Tg4OOgtRSUPw4cPR1RUFHbt2oWqVasWWrZJkyYAgLi4J3dwdXd3z/fmkTnbDMXkgYiISIbSHqophMDw4cOxadMm7Ny5Ez4+PkXuc/z4cQBA5cqVAQCBgYE4deoUkpKSpDLR0dFwcHCAv79/fofIF5stiIiIyoBhw4YhMjISv/zyC+zt7aU+Co6OjrC2tsbFixcRGRmJ9u3bo2LFijh58iRGjx6Nli1bon79+gCA4OBg+Pv7491338Xs2bORkJCAjz/+GMOGDTPqDtNMHoiIiGQo7aGaS5YsAfBkIqinrVq1Cn369IFarcb27dulu0l7enqiW7du+Pjjj6Wy5ubmiIqKwpAhQxAYGAhbW1uEhYXpzQthCCYPREREMpR28iCEKHS7p6cn9uzZU+RxvL298fvvvxt17tzY54GIiIiMwpoHIiIiGcrzLbmZPBAREckghArChATAlH2VxmYLIiIiMgprHoiIiGTImezJlP3LKiYPREREMpTnPg9stiAiIiKjsOaBiIhIhvLcYZLJAxERkQzludmCyQMREZEM5bnmgX0eiIiIyCiseSAiIpJBmNhsUZZrHpg8EBERySAAFHGvqiL3L6vYbEFERERGYc0DERGRDDqooOIMk0RERGQojrYgIiIiMhBrHoiIiGTQCRVUnCSKiIiIDCWEiaMtyvBwCzZbEBERkVFY80BERCRDee4wyeSBiIhIBiYPREREZJTy3GGSfR6IiIjIKKx5ICIikqE8j7Zg8kBERCTDk+TBlD4PxRhMKWOzBRERERmFNQ9EREQycLQFERERGUX8bzFl/7KKzRZERERkFNY8EBERycBmCyIiIjJOOW63YPJAREQkh4k1DyjDNQ/s80BERERGYc0DERGRDJxhkoiIiIxSnjtMstmCiIiIjMKaByIiIjmEyrROj2W45oHJAxERkQzluc8Dmy2IiIjIKKx5ICIikoOTRJWuX3/91eCynTp1KsFIiIiI5CnPoy0USR66dOliUDmVSgWtVluywRAREZFRFEkedDqdEqclIiIqXmW46cEUz1Sfh/T0dFhZWSkdBhERUZHKc7OF4qMttFotPvnkE1SpUgV2dna4dOkSAGDKlClYsWKFwtEREREVQBTDUkYpnjzMmjULERERmD17NtRqtbS+bt26WL58uYKRERERUX4UTx7WrFmDZcuWoXfv3jA3N5fWN2jQAGfPnlUwMiIiosKoimEpmxTv83Djxg3UqFEjz3qdToesrCwFIiIiIjJAOZ7nQfGaB39/f+zbty/P+o0bN+LFF19UICIiIiIqjOI1D1OnTkVYWBhu3LgBnU6Hn3/+GefOncOaNWsQFRWldHhERET5Y82Dcjp37owtW7Zg+/btsLW1xdSpUxEbG4stW7bgtddeUzo8IiKi/OXcVdOUpYxSvOYBAFq0aIHo6GilwyAiIiIDPBPJAwAcPnwYsbGxAJ70gwgICFA4IiIiooKV51tyK548XL9+HW+99Rb2798PJycnAMD9+/fxyiuvYP369ahataqyARIREeWHfR6UM2DAAGRlZSE2NhbJyclITk5GbGwsdDodBgwYoHR4RERElIviNQ979uzBgQMHULt2bWld7dq1sWDBArRo0ULByIiIiAphaqdHdpiUz9PTM9/JoLRaLTw8PBSIiIiIqGgq8WQxZf+ySvFmizlz5mDEiBE4fPiwtO7w4cP44IMP8MUXXygYGRERUSHK8Y2xFKl5qFChAlSq/6pr0tLS0KRJE1hYPAknOzsbFhYW6NevH7p06aJEiERERFQARZKHefPmKXFaIiKi4sM+D6UrLCxMidMSEREVn3I8VFPxDpNPS09PR2Zmpt46BwcHhaIhIiKi/CjeYTItLQ3Dhw+Hq6srbG1tUaFCBb2FiIjomVSOO0wqnjxMmDABO3fuxJIlS6DRaLB8+XLMmDEDHh4eWLNmjdLhERER5a+Uk4fw8HA0btwY9vb2cHV1RZcuXXDu3Dm9Munp6Rg2bBgqVqwIOzs7dOvWDYmJiXplrl69ig4dOsDGxgaurq4YP348srOzjYpF8eRhy5YtWLx4Mbp16wYLCwu0aNECH3/8MT777DOsW7dO6fCIiIieCXv27MGwYcPw999/Izo6GllZWQgODkZaWppUZvTo0diyZQs2bNiAPXv24ObNm+jatau0XavVokOHDsjMzMSBAwewevVqREREYOrUqUbFonifh+TkZPj6+gJ40r8hOTkZANC8eXMMGTJEydCIiIgKVsqjLbZt26b3OCIiAq6urjhy5AhatmyJBw8eYMWKFYiMjMSrr74KAFi1ahXq1KmDv//+G02bNsWff/6Jf//9F9u3b4ebmxsaNmyITz75BBMnTsT06dOhVqsNikXxmgdfX1/Ex8cDAPz8/PDjjz8CeFIjkXOjLCIiomdNzgyTpiwAkJKSordkZGQYdP4HDx4AAJydnQEAR44cQVZWFoKCgqQyfn5+8PLyQkxMDAAgJiYG9erVg5ubm1QmJCQEKSkpOHPmjMH/u+LJQ9++fXHixAkAwKRJk7Bo0SJYWVlh9OjRGD9+vMLRERERlSxPT084OjpKS3h4eJH76HQ6jBo1Cs2aNUPdunUBAAkJCVCr1Xl+eLu5uSEhIUEq83TikLM9Z5uhFG+2GD16tPR3UFAQzp49iyNHjqBGjRqoX7++gpEREREVopjmebh27ZretAQajabIXYcNG4bTp0/jr7/+MiEA+RRPHnLz9vaGt7e30mEQERGVCgcHB6PmNBo+fDiioqKwd+9eVK1aVVrv7u6OzMxM3L9/X6/2ITExEe7u7lKZQ4cO6R0vZzRGThlDKJI8zJ8/3+CyI0eOLMFIiIiI5FHBxLtqGlleCIERI0Zg06ZN2L17N3x8fPS2BwQEwNLSEjt27EC3bt0AAOfOncPVq1cRGBgIAAgMDMSsWbOQlJQEV1dXAEB0dDQcHBzg7+9vcCyKJA9fffWVQeVUKhWTByIiIjxpqoiMjMQvv/wCe3t7qY+Co6MjrK2t4ejoiP79+2PMmDFwdnaGg4MDRowYgcDAQDRt2hQAEBwcDH9/f7z77ruYPXs2EhIS8PHHH2PYsGEGNZfkUCR5yBld8Szr3qQFLFSGDVkhKmse9qqtdAhEJSI7Kx3Y+EvpnKyUh2ouWbIEANC6dWu99atWrUKfPn0APPlxbmZmhm7duiEjIwMhISFYvHixVNbc3BxRUVEYMmQIAgMDYWtri7CwMMycOdOoWJ65Pg9ERERlQinfGEuIonewsrLCokWLsGjRogLLeHt74/fffzfu5LkoPlSTiIiIyhbWPBAREcnBW3ITERGRMZ6eJVLu/mUVmy2IiIjIKM9E8rBv3z688847CAwMxI0bNwAAa9euVWzmLCIioiKV8i25nyWKJw8//fQTQkJCYG1tjWPHjkk3BHnw4AE+++wzhaMjIiIqAJMH5Xz66adYunQpvv32W1haWkrrmzVrhqNHjyoYGREREeVH8Q6T586dQ8uWLfOsd3R0xP3790s/ICIiIgOww6SC3N3dERcXl2f9X3/9BV9fXwUiIiIiMkDODJOmLGWU4snDwIED8cEHH+DgwYNQqVS4efMm1q1bh3HjxmHIkCFKh0dERJS/ctznQfFmi0mTJkGn06Ft27Z49OgRWrZsCY1Gg3HjxmHEiBFKh0dERES5KJ48qFQqfPTRRxg/fjzi4uKQmpoKf39/2NnZKR0aERFRgcpznwfFk4ccarXaqHuJExERKYrTUyunTZs2UKkK7jSyc+fOUoyGiIiIiqJ48tCwYUO9x1lZWTh+/DhOnz6NsLAwZYIiIiIqionNFqx5MMFXX32V7/rp06cjNTW1lKMhIiIyUDlutlB8qGZB3nnnHaxcuVLpMIiIiCgXxWseChITEwMrKyulwyAiIspfOa55UDx56Nq1q95jIQRu3bqFw4cPY8qUKQpFRUREVDgO1VSQo6Oj3mMzMzPUrl0bM2fORHBwsEJRERERUUEUTR60Wi369u2LevXqoUKFCkqGQkRERAZStMOkubk5goODefdMIiIqe8rxvS0UH21Rt25dXLp0SekwiIiIjJLT58GUpaxSPHn49NNPMW7cOERFReHWrVtISUnRW4iIiOjZolifh5kzZ2Ls2LFo3749AKBTp05601QLIaBSqaDVapUKkYiIqHBluPbAFIolDzNmzMD777+PXbt2KRUCERGRfJznofQJ8eRZa9WqlVIhEBERkQyKDtUs7G6aREREzzJOEqWQWrVqFZlAJCcnl1I0RERERmCzhTJmzJiRZ4ZJIiIierYpmjz06tULrq6uSoZAREQkC5stFMD+DkREVKaV42YLxSaJyhltQURERGWLYjUPOp1OqVMTERGZrhzXPCh+S24iIqKyiH0eiIiIyDjluOZB8RtjERERUdnCmgciIiI5ynHNA5MHIiIiGcpznwc2WxAREZFRWPNAREQkB5stiIiIyBhstiAiIiIyEGseiIiI5GCzBRERERmlHCcPbLYgIiIio7DmgYiISAbV/xZT9i+rmDwQERHJUY6bLZg8EBERycChmkREREQGYs0DERGRHGy2ICIiIqOV4QTAFGy2ICIiIqOw5oGIiEiG8txhkskDERGRHOW4zwObLYiIiMgorHkgIiKSgc0WREREZBw2WxAREREZhjUPREREMrDZgoiIiIxTjpstmDwQERHJUY6TB/Z5ICIiIqOw5oGIiEiG8tzngTUPREREcohiWIy0d+9edOzYER4eHlCpVNi8ebPe9j59+kClUukt7dq10yuTnJyM3r17w8HBAU5OTujfvz9SU1ONioPJAxERURmRlpaGBg0aYNGiRQWWadeuHW7duiUt33//vd723r1748yZM4iOjkZUVBT27t2LQYMGGRUHmy2IiIhkUAkBlZDf9iBn39DQUISGhhZaRqPRwN3dPd9tsbGx2LZtG/755x80atQIALBgwQK0b98eX3zxBTw8PAyKgzUPREREcijQbGGI3bt3w9XVFbVr18aQIUNw9+5daVtMTAycnJykxAEAgoKCYGZmhoMHDxp8DtY8EBERKSglJUXvsUajgUajkXWsdu3aoWvXrvDx8cHFixfx4YcfIjQ0FDExMTA3N0dCQgJcXV319rGwsICzszMSEhIMPg+TByIiIhmKa7SFp6en3vpp06Zh+vTpso7Zq1cv6e969eqhfv36qF69Onbv3o22bdvKDTUPJg9ERERyFNMkUdeuXYODg4O0Wm6tQ358fX1RqVIlxMXFoW3btnB3d0dSUpJemezsbCQnJxfYTyI/7PNARESkIAcHB72lOJOH69ev4+7du6hcuTIAIDAwEPfv38eRI0ekMjt37oROp0OTJk0MPi5rHoiIiGRQYpKo1NRUxMXFSY/j4+Nx/PhxODs7w9nZGTNmzEC3bt3g7u6OixcvYsKECahRowZCQkIAAHXq1EG7du0wcOBALF26FFlZWRg+fDh69epl8EgLgDUPRERE8igw2uLw4cN48cUX8eKLLwIAxowZgxdffBFTp06Fubk5Tp48iU6dOqFWrVro378/AgICsG/fPr3ajHXr1sHPzw9t27ZF+/bt0bx5cyxbtsyoOFjzQEREJIMSNQ+tW7eGKGR+iD/++KPIYzg7OyMyMtL4kz+FNQ9ERERkFNY8EBERyVGOb8nN5IGIiEimsnxnTFOw2YKIiIiMwpoHIiIiOYR4spiyfxnF5IGIiEgGJUZbPCvYbEFERERGYc0DERGRHBxtQURERMZQ6Z4spuxfVrHZgoiIiIzCmgcqcWZmAr2HXUab1xNRoVImkpPU2P6LO75f6g1AJZXz9E1D3zGXUK/RfZibC1y9ZItZo17A7VtWygVPlI+GvjfxdpsTqF31DlwcH2HSymDsPe2Tb9nx3ffijVdiMW9zIH7cW19a/3m/bahZ5S4q2D3Gw8caHD5fBYujmuBOim1p/RtkqnLcbPFc1Tzs3bsXHTt2hIeHB1QqFTZv3qx0SASge/+raN/zBpbMqonBHRtj5Ve+6NbvGjr1viGVcfd8jDlrj+F6vA0m9mmIoV0b4/ul3sjMeK4uUXpOWKmzEXezIub+3LzQci3rxeMF7yTcfmCTZ9vROA9MWROEt/6vJz6MeA1VKqZgVlh0SYVMJSBntIUpS1n1XNU8pKWloUGDBujXrx+6du2qdDj0P/4NH+DvnZXwz96KAICkm9Zo3T4JteqlSGXCRl7C4b0VsXJudWldwjXrUo+VyBB/n/XC32e9Ci1TyTENY97Yj9HftMcXA7fm2f7DU7UQCffssXZnQ/xf3z9gbqaFVmde7DFTCeA8D8+H0NBQhIaGKh0G5fLvcUeEvnkTVbwf4cYVG/jUToX/iw/w7ewaAACVSqBxq2T8tNITnyw7gep+qUi8YYUfv/VCzE4XhaMnMp5KJTDt7Z2I3NUA8YnORZa3t0lH8EsXcOqyOxMHKhOeq+RBjoyMDGRkZEiPU1JSCilNcmxY7gUbu2x8E3UIOq0KZuYCa772we7f3AAAThUzYWOrxZv9r2LNAh+s+tIXAc2T8dHXZzCpb0OcPuyk7D9AZKR3Xj0Orc4MP+6rW2i5oa//jW7NzsBak43Tl10xbjl//JQl5XmSqHKfPISHh2PGjBlKh/Fca9EuCW06JGH2hDq4GmcLX79UDJoUh7u3NdjxiztU/+sz+feuSti8xhMAcOmsPeo0TEH7njeZPFCZUrvqbfRocQp9v+yGpzsE52fdrgbYctAP7hVS0S/4CKa+vQvjlrcrcj96RpTjDpPlPnmYPHkyxowZIz1OSUmBp6enghE9f/qPvYQNK7ywd+uTmobLF+zg6pGOHgOuYMcv7ki5b4nsLBWuXtTvVHbtkg1eeOmBEiETydbA9xYq2D3Gz1PWSesszAVGdPobPVueQrdPe0vrH6RZ40GaNa7ddsLlRCf8Mm0d6non4vQVdyVCJzJYuU8eNBoNNBqN0mE81zTWWuhyTYai06pg9r+BFNlZZjh/2h5Vqz3WK1PF+zGSbnKYJpUt2w7XwuHzVfXWfTX4N2w7XAu/Hapd4H5m/6vDtrQowzMHlTNstiAqQQd3V0SvQVdw+5YVrsTZoHqdVLwRdh1/bvrv19VPqzwxae6/OHXEEScPOSGgeTKatL6DiX0bKhc4UQGs1VmoWum/WrHKzg9R0+MOUh5pkHjfHimP9JPebK0Z7j60xtXbTgAAf69E1PG6jZOX3PHwsQZVKqZgYOg/uH7HAacvu5Xmv0Km4GiL50Nqairi4uKkx/Hx8Th+/DicnZ3h5VX4sCoqOUtn1cS7I+MxbMp5ODpnITlJja0bKiNySTWpTMwOFyycUQs9Bl7F+5PjcP2yNWaNqot/jzopFjdRQfw8b2PRsC3S4w+6xAAAfjtUC7PWtyly//QsC7SuF48BIYdhpc7G3RQb/H3WExHbX0KWlqMt6NmnEqIMpz657N69G23a5H3jhoWFISIiwqBjpKSkwNHREW0rhMFCpS7mCImeDfdDCq4+JyrLsrPScWTjx3jw4AEcHBxK5Bw53xOBoTNhYSm/aTU7Kx0xW6eWaKwl5bmqeWjdujWeo1yIiIieZeV4tAXn/iUiIiKjPFc1D0RERKWFoy2IiIjIODrxZDFl/zKKyQMREZEc7PNAREREZBjWPBAREcmggol9HootktLH5IGIiEiOcjzDJJstiIiIyCiseSAiIpKBQzWJiIjIOBxtQURERGQY1jwQERHJoBICKhM6PZqyr9KYPBAREcmh+99iyv5lFJstiIiIyCiseSAiIpKBzRZERERknHI82oLJAxERkRycYZKIiIjIMKx5ICIikoEzTBIREZFx2GxBREREZBjWPBAREcmg0j1ZTNm/rGLyQEREJAebLYiIiIgMw5oHIiIiOThJFBERERmjPE9PzWYLIiIiMgprHoiIiOQoxx0mmTwQERHJIQCYMtyy7OYOTB6IiIjkYJ8HIiIiIgOx5oGIiEgOARP7PBRbJKWOyQMREZEc5bjDJJstiIiIyCiseSAiIpJDB0Bl4v5lFJMHIiIiGTjagoiIiMhArHkgIiKSoxx3mGTyQEREJEc5Th7YbEFERERGYc0DERGRHOW45oHJAxERkRzleKgmmy2IiIhkyBmqacpirL1796Jjx47w8PCASqXC5s2b9bYLITB16lRUrlwZ1tbWCAoKwoULF/TKJCcno3fv3nBwcICTkxP69++P1NRUo+Jg8kBERFRGpKWloUGDBli0aFG+22fPno358+dj6dKlOHjwIGxtbRESEoL09HSpTO/evXHmzBlER0cjKioKe/fuxaBBg4yKg80WREREcijQ5yE0NBShoaEFHE5g3rx5+Pjjj9G5c2cAwJo1a+Dm5obNmzejV69eiI2NxbZt2/DPP/+gUaNGAIAFCxagffv2+OKLL+Dh4WFQHKx5ICIikkMnTF+KUXx8PBISEhAUFCStc3R0RJMmTRATEwMAiImJgZOTk5Q4AEBQUBDMzMxw8OBBg8/FmgciIiIFpaSk6D3WaDTQaDRGHychIQEA4Obmprfezc1N2paQkABXV1e97RYWFnB2dpbKGII1D0RERHLkNFuYsgDw9PSEo6OjtISHhyv8jxWNNQ9ERESymNjnAU/2vXbtGhwcHKS1cmodAMDd3R0AkJiYiMqVK0vrExMT0bBhQ6lMUlKS3n7Z2dlITk6W9jcEax6IiIgU5ODgoLfITR58fHzg7u6OHTt2SOtSUlJw8OBBBAYGAgACAwNx//59HDlyRCqzc+dO6HQ6NGnSxOBzseaBiIhIDgVGW6SmpiIuLk56HB8fj+PHj8PZ2RleXl4YNWoUPv30U9SsWRM+Pj6YMmUKPDw80KVLFwBAnTp10K5dOwwcOBBLly5FVlYWhg8fjl69ehk80gJg8kBERCSPTiCn6UH+/sY5fPgw2rRpIz0eM2YMACAsLAwRERGYMGEC0tLSMGjQINy/fx/NmzfHtm3bYGVlJe2zbt06DB8+HG3btoWZmRm6deuG+fPnGxUHkwciIqIyonXr1hCF1FioVCrMnDkTM2fOLLCMs7MzIiMjTYqDyQMREZEcQvdkMWX/MorJAxERkRy8qyYREREZRYE+D88KDtUkIiIio7DmgYiISA42WxAREZFRBExMHootklLHZgsiIiIyCmseiIiI5GCzBRERERlFpwNgwlwNurI7zwObLYiIiMgorHkgIiKSg80WREREZJRynDyw2YKIiIiMwpoHIiIiOcrx9NRMHoiIiGQQQgdhwp0xTdlXaUweiIiI5BDCtNoD9nkgIiKi8oI1D0RERHIIE/s8lOGaByYPREREcuh0gMqEfgtluM8Dmy2IiIjIKKx5ICIikoPNFkRERGQModNBmNBsUZaHarLZgoiIiIzCmgciIiI52GxBRERERtEJQFU+kwc2WxAREZFRWPNAREQkhxAATJnnoezWPDB5ICIikkHoBIQJzRaCyQMREVE5I3QwreaBQzWJiIionGDNAxERkQxstiAiIiLjlONmCyYPueRkgtkiU+FIiEpOdla60iEQlQjt/67t0vhVn40sk+aIykZW8QVTypg85PLw4UMAwJ773yscCVEJ2qh0AEQl6+HDh3B0dCyRY6vVari7u+OvhN9NPpa7uzvUanUxRFW6VKIsN7qUAJ1Oh5s3b8Le3h4qlUrpcJ57KSkp8PT0xLVr1+Dg4KB0OETFjtd46RJC4OHDh/Dw8ICZWcmNCUhPT0dmpuk11Gq1GlZWVsUQUelizUMuZmZmqFq1qtJhlDsODg78YKXnGq/x0lNSNQ5Ps7KyKpNf+sWFQzWJiIjIKEweiIiIyChMHkhRGo0G06ZNg0ajUToUohLBa5yeR+wwSUREREZhzQMREREZhckDERERGYXJAxERERmFyQMREREZhckDKWbRokWoVq0arKys0KRJExw6dEjpkIiKzd69e9GxY0d4eHhApVJh8+bNSodEVGyYPJAifvjhB4wZMwbTpk3D0aNH0aBBA4SEhCApKUnp0IiKRVpaGho0aIBFixYpHQpRseNQTVJEkyZN0LhxYyxcuBDAk3uKeHp6YsSIEZg0aZLC0REVL5VKhU2bNqFLly5Kh0JULFjzQKUuMzMTR44cQVBQkLTOzMwMQUFBiImJUTAyIiIyBJMHKnV37tyBVquFm5ub3no3NzckJCQoFBURERmKyQMREREZhckDlbpKlSrB3NwciYmJeusTExPh7u6uUFRERGQoJg9U6tRqNQICArBjxw5pnU6nw44dOxAYGKhgZEREZAgLpQOg8mnMmDEICwtDo0aN8PLLL2PevHlIS0tD3759lQ6NqFikpqYiLi5OehwfH4/jx4/D2dkZXl5eCkZGZDoO1STFLFy4EHPmzEFCQgIaNmyI+fPno0mTJkqHRVQsdu/ejTZt2uRZHxYWhoiIiNIPiKgYMXkgIiIio7DPAxERERmFyQMREREZhckDERERGYXJAxERERmFyQMREREZhckDERERGYXJAxERERmFyQPRM6hPnz7o0qWL9Lh169YYNWpUqcexe/duqFQq3L9/v8AyKpUKmzdvNviY06dPR8OGDU2K6/Lly1CpVDh+/LhJxyEieZg8EBmoT58+UKlUUKlUUKvVqFGjBmbOnIns7OwSP/fPP/+MTz75xKCyhnzhExGZgve2IDJCu3btsGrVKmRkZOD333/HsGHDYGlpicmTJ+cpm5mZCbVaXSzndXZ2LpbjEBEVB9Y8EBlBo9HA3d0d3t7eGDJkCIKCgvDrr78C+K+pYdasWfDw8EDt2rUBANeuXUOPHj3g5OQEZ2dndO7cGZcvX5aOqdVqMWbMGDg5OaFixYqYMGECcs8an7vZIiMjAxMnToSnpyc0Gg1q1KiBFStW4PLly9L9FCpUqACVSoU+ffoAeHLn0vDwcPj4+MDa2hoNGjTAxo0b9c7z+++/o1atWrC2tkabNm304jTUxIkTUatWLdjY2MDX1xdTpkxBVlZWnnLffPMNPD09YWNjgx49euDBgwd625cvX446derAysoKfn5+WLx4sdGxEFHJYPJAZAJra2tkZmZKj3fs2IFz584hOjoaUVFRyMrKQkhICOzt7bFv3z7s378fdnZ2aNeunbTf3LlzERERgZUrV+Kvv/5CcnIyNm3aVOh533vvPXz//feYP38+YmNj8c0338DOzg6enp746aefAADnzp3DrVu38PXXXwMAwsPDsWbNGixduhRnzpzB6NGj8c4772DPnj0AniQ5Xbt2RceOHXH8+HEMGDAAkyZNMvo5sbe3R0REBP799198/fXX+Pbbb/HVV1/plYmLi8OPP/6ILVu2YNu2bTh27BiGDh0qbV+3bh2mTp2KWbNmITY2Fp999hmmTJmC1atXGx0PEZUAQUQGCQsLE507dxZCCKHT6UR0dLTQaDRi3Lhx0nY3NzeRkZEh7bN27VpRu3ZtodPppHUZGRnC2tpa/PHHH0IIISpXrixmz54tbc/KyhJVq1aVziWEEK1atRIffPCBEEKIc+fOCQAiOjo63zh37dolAIh79+5J69LT04WNjY04cOCAXtn+/fuLt956SwghxOTJk4W/v7/e9okTJ+Y5Vm4AxKZNmwrcPmfOHBEQECA9njZtmjA3NxfXr1+X1m3dulWYmZmJW7duCSGEqF69uoiMjNQ7zieffCICAwOFEELEx8cLAOLYsWMFnpeISg77PBAZISoqCnZ2dsjKyoJOp8Pbb7+N6dOnS9vr1aun18/hxIkTiIuLg729vd5x0tPTcfHiRTx48AC3bt3SuxW5hYUFGjVqlKfpIsfx48dhbm6OVq1aGRx3XFwcHj16hNdee01vfWZmJl588UUAQGxsbJ5bogcGBhp8jhw//PAD5s+fj4sXLyI1NRXZ2dlwcHDQK+Pl5YUqVaronUen0+HcuXOwt7fHxYsX0b9/fwwcOFAqk52dDUdHR6PjIaLix+SByAht2rTBkiVLoFar4eHhAQsL/beQra2t3uPU1FQEBARg3bp1eY7l4uIiKwZra2uj90lNTQUA/Pbbb3pf2sCTfhzFJSYmBr1798aMGTMQEhICR0dHrF+/HnPnzjU61m+//TZPMmNubl5ssRKRfEweiIxga2uLGjVqGFz+pZdewg8//ABXV9c8v75zVK5cGQcPHkTLli0BPPmFfeTIEbz00kv5lq9Xrx50Oh327NmDoKCgPNtzaj60Wq20zt/fHxqNBlevXi2wxqJOnTpS588cf//9d9H/5FMOHDgAb29vfPTRR9K6K1eu5Cl39epV3Lx5Ex4eHtJ5zMzMULt2bbi5ucHDwwOXLl1C7969jTo/EZUOdpgkKkG9e/dGpUqV0LlzZ+zbtw/x8fHYvXs3Ro4cievXrwMAPvjgA/zf//0fNm/ejLNnz2Lo0KGFztFQrVo1hIWFoV+/fti8ebN0zB9//BEA4O3tDZVKhaioKNy+fRupqamwt7fHuHHjMHr0aKxevRoXL17E0aNHsWDBAqkT4vvvv48LFy5g/PjxOHfuHCIjIxEREWHU/1uzZk1cvXoV69evx8WLFzF//vx8O39aWVkhLCwMJ06cwL59+zBy5Ej06NED7u7uAIAZM2YgPDwc8+fPx/nz53Hq1CmsWrUKX375pVHxEFHJYPJAVIJsbGywd+9eeHl5oWvXrqhTpw769++P9PR0qSZi7NixePfddxEWFobAwEDY29vjjTfeKPS4S5YsQffu3TF06FD4+flh4MCBSEtLAwBUqVIFM2bMwKRJk+Dm5obhw4cDAD755BNMmTIF4eHhqFOnDtq1a4fffvsNPj4+AJ70Q/jpp5+wefNmNGjQAEuXLsVnn31m1P/bqVMnjB49GsOHD0fDhg1x4MABTJkyJU+5GjVqoGvXrmjfvj2Cg4NRv359vaGYAwYMwPLly7Fq1SrUq1cPrVq1QkREhBQrESlLJQrqlUVERESUD9Y8EBERkVGYPBAREZFRmDwQERGRUZg8EBERkVGYPBAREZFRmDwQERGRUZg8EBERkVGYPBAREZFRmDwQERGRUZg8EBERkVGYPBAREZFRmDwQERGRUf4fcM40nVD75i0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define the objective function for optimization\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)  # Number of trees\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 1.0, log=True)  # Learning rate\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 5)  # Maximum depth of each tree\n",
    "\n",
    "    # Create the model with suggested hyperparameters\n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators,learning_rate=learning_rate,max_depth=max_depth,random_state=0)\n",
    "    \n",
    "    # Evaluate the model using cross-validation\n",
    "    scores = cross_val_score(model, X_mushroom_train, y_mushroom_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Return the mean cross-validation accuracy\n",
    "    return scores.mean()\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials\n",
    "\n",
    "# Print the best hyperparameters and their performance\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best cross-validation accuracy: {study.best_value}\")\n",
    "\n",
    "# Retrieve the best model\n",
    "best_params = study.best_params\n",
    "best_model = GradientBoostingClassifier(**best_params, random_state=0)\n",
    "y_pred = evaluate_model(\"Mushroom\", best_model, X_mushroom_train, y_mushroom_train, X_mushroom_test, y_mushroom_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves for Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure for the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr, label):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "\n",
    "# List of classifiers and their predictions\n",
    "models = {\n",
    "    \"Gradient Boosting\": y_pred[1]\n",
    "}\n",
    "\n",
    "# Loop through each model to calculate and plot ROC curves\n",
    "for name, predictions in models.items():\n",
    "    # Use predict_proba for SVM and others that support it\n",
    "    y_pred_proba = predictions  # For other models, use the predicted classes\n",
    "\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_mushroom_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_mushroom_test, y_pred_proba)\n",
    "    plot_roc_curve(fpr, tpr, f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "# Finalize the ROC curve plot\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Data into Labeled and Unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1262\n",
      "Labeled samples: 126\n",
      "Unlabeled samples: 1136\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(y_mushroom_train)\n",
    "num_labeled = int(0.1 * num_samples)\n",
    "labeled_indices = np.random.choice(num_samples, num_labeled, replace=False)\n",
    "\n",
    "y_mushroom_train_unlabeled = np.full_like(y_mushroom_train, fill_value=-1)\n",
    "y_mushroom_train_unlabeled[labeled_indices] = y_mushroom_train[labeled_indices]\n",
    "\n",
    "print(f\"Total samples: {num_samples}\")\n",
    "print(f\"Labeled samples: {np.sum(y_mushroom_train_unlabeled != -1)}\")\n",
    "print(f\"Unlabeled samples: {np.sum(y_mushroom_train_unlabeled == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Training with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Self-Training with Gradient Boosting: 0.6822\n"
     ]
    }
   ],
   "source": [
    "self_training_model = SelfTrainingClassifier(GradientBoostingClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=0))\n",
    "\n",
    "self_training_model.fit(X_mushroom_train, y_mushroom_train_unlabeled)\n",
    "\n",
    "# Train the self-training model and evaluate its performance\n",
    "y_pred = self_training_model.predict(X_mushroom_test)\n",
    "accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Self-Training with Gradient Boosting: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-training with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(\n",
    "    X_mushroom_train, y_mushroom_train, test_size=0.9, stratify=y_mushroom_train\n",
    ")\n",
    "\n",
    "num_features = X_labeled.shape[1]\n",
    "X_labeled_view1, X_labeled_view2 = X_labeled.iloc[:, :num_features // 2], X_labeled.iloc[:, num_features // 2:]\n",
    "X_unlabeled_view1, X_unlabeled_view2 = X_unlabeled.iloc[:, :num_features // 2], X_unlabeled.iloc[:, num_features // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 16:32:09,769] A new study created in memory with name: no-name-b51f3529-8053-4b98-8425-0daa306e583f\n",
      "[I 2024-12-02 16:32:10,572] Trial 0 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 198, 'learning_rate': 0.011319473651413704, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:11,944] Trial 1 finished with value: 0.7464991530208922 and parameters: {'n_estimators': 200, 'learning_rate': 0.46042941421656813, 'max_depth': 4}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:12,645] Trial 2 finished with value: 0.7353692201518289 and parameters: {'n_estimators': 77, 'learning_rate': 0.9336042767028181, 'max_depth': 5}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:13,273] Trial 3 finished with value: 0.7686586360499403 and parameters: {'n_estimators': 117, 'learning_rate': 0.1976247760670793, 'max_depth': 3}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:13,596] Trial 4 finished with value: 0.7821099190664407 and parameters: {'n_estimators': 62, 'learning_rate': 0.05820123598404528, 'max_depth': 3}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:14,634] Trial 5 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 148, 'learning_rate': 0.022573325622917726, 'max_depth': 4}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:15,112] Trial 6 finished with value: 0.7805320283581153 and parameters: {'n_estimators': 117, 'learning_rate': 0.1705813327513073, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:15,373] Trial 7 finished with value: 0.7829129807390677 and parameters: {'n_estimators': 50, 'learning_rate': 0.01886636682299591, 'max_depth': 3}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:15,937] Trial 8 finished with value: 0.7773731099818055 and parameters: {'n_estimators': 113, 'learning_rate': 0.10492313847990833, 'max_depth': 3}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:16,790] Trial 9 finished with value: 0.7227209988079553 and parameters: {'n_estimators': 127, 'learning_rate': 0.7591100299404476, 'max_depth': 4}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:17,238] Trial 10 finished with value: 0.7781510759771628 and parameters: {'n_estimators': 200, 'learning_rate': 0.012693431533038695, 'max_depth': 1}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:17,604] Trial 11 finished with value: 0.7734017190538929 and parameters: {'n_estimators': 162, 'learning_rate': 0.011068282095777414, 'max_depth': 1}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:17,919] Trial 12 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 85, 'learning_rate': 0.029610933425418384, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:18,278] Trial 13 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 89, 'learning_rate': 0.03685668105153985, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:18,916] Trial 14 finished with value: 0.7852970700796786 and parameters: {'n_estimators': 173, 'learning_rate': 0.03784808838622548, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:19,529] Trial 15 finished with value: 0.7821193299454169 and parameters: {'n_estimators': 174, 'learning_rate': 0.05168133894746862, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:19,934] Trial 16 finished with value: 0.7734017190538929 and parameters: {'n_estimators': 180, 'learning_rate': 0.010471873197244366, 'max_depth': 1}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:20,456] Trial 17 finished with value: 0.7797415145241231 and parameters: {'n_estimators': 147, 'learning_rate': 0.06648140369010978, 'max_depth': 2}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:20,870] Trial 18 finished with value: 0.7805320283581153 and parameters: {'n_estimators': 184, 'learning_rate': 0.018361680267924178, 'max_depth': 1}. Best is trial 0 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 16:32:21,442] Trial 19 finished with value: 0.7860907208733294 and parameters: {'n_estimators': 161, 'learning_rate': 0.03568503306020935, 'max_depth': 2}. Best is trial 19 with value: 0.7860907208733294.\n",
      "[I 2024-12-02 16:32:22,806] Trial 20 finished with value: 0.7567946546207416 and parameters: {'n_estimators': 153, 'learning_rate': 0.09351006989442312, 'max_depth': 5}. Best is trial 19 with value: 0.7860907208733294.\n",
      "[I 2024-12-02 16:32:23,409] Trial 21 finished with value: 0.7876717485413136 and parameters: {'n_estimators': 168, 'learning_rate': 0.035036777494143315, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:24,102] Trial 22 finished with value: 0.7853002070393375 and parameters: {'n_estimators': 189, 'learning_rate': 0.02566663180860317, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:24,416] Trial 23 finished with value: 0.7757795344751865 and parameters: {'n_estimators': 137, 'learning_rate': 0.01580406023520021, 'max_depth': 1}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:24,995] Trial 24 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 163, 'learning_rate': 0.040858813989060674, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:25,794] Trial 25 finished with value: 0.7781636238157977 and parameters: {'n_estimators': 161, 'learning_rate': 0.0916953694614398, 'max_depth': 3}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:26,467] Trial 26 finished with value: 0.7813350900307421 and parameters: {'n_estimators': 192, 'learning_rate': 0.1741241050702299, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:27,319] Trial 27 finished with value: 0.7813319530710835 and parameters: {'n_estimators': 170, 'learning_rate': 0.028067301318162076, 'max_depth': 3}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:27,640] Trial 28 finished with value: 0.7757795344751865 and parameters: {'n_estimators': 140, 'learning_rate': 0.015456997516325711, 'max_depth': 1}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:28,621] Trial 29 finished with value: 0.7425058033753686 and parameters: {'n_estimators': 197, 'learning_rate': 0.3173215832670402, 'max_depth': 3}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:29,265] Trial 30 finished with value: 0.7789478637304723 and parameters: {'n_estimators': 183, 'learning_rate': 0.0684670631649027, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:29,936] Trial 31 finished with value: 0.7853002070393375 and parameters: {'n_estimators': 190, 'learning_rate': 0.025251089478957246, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:30,601] Trial 32 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 188, 'learning_rate': 0.02136797131208528, 'max_depth': 2}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:31,002] Trial 33 finished with value: 0.7781510759771628 and parameters: {'n_estimators': 178, 'learning_rate': 0.014368492138310561, 'max_depth': 1}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:31,996] Trial 34 finished with value: 0.7836972206537423 and parameters: {'n_estimators': 200, 'learning_rate': 0.020551204114119044, 'max_depth': 3}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:33,114] Trial 35 finished with value: 0.7781698977351151 and parameters: {'n_estimators': 167, 'learning_rate': 0.05023632792968625, 'max_depth': 4}. Best is trial 21 with value: 0.7876717485413136.\n",
      "[I 2024-12-02 16:32:33,675] Trial 36 finished with value: 0.7892590501286152 and parameters: {'n_estimators': 156, 'learning_rate': 0.035594721189764915, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:34,251] Trial 37 finished with value: 0.7892590501286152 and parameters: {'n_estimators': 155, 'learning_rate': 0.035622879900724894, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:35,013] Trial 38 finished with value: 0.7741953698475438 and parameters: {'n_estimators': 151, 'learning_rate': 0.04511616349323807, 'max_depth': 3}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:35,311] Trial 39 finished with value: 0.7845034192860278 and parameters: {'n_estimators': 130, 'learning_rate': 0.03178055745896188, 'max_depth': 1}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:35,867] Trial 40 finished with value: 0.7773605621431707 and parameters: {'n_estimators': 155, 'learning_rate': 0.11707931332982169, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:36,368] Trial 41 finished with value: 0.7884653993349645 and parameters: {'n_estimators': 140, 'learning_rate': 0.033380134952973206, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:36,873] Trial 42 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 142, 'learning_rate': 0.058211029779133956, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:37,263] Trial 43 finished with value: 0.7852876592007026 and parameters: {'n_estimators': 107, 'learning_rate': 0.021806289412285115, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:37,704] Trial 44 finished with value: 0.7853002070393375 and parameters: {'n_estimators': 122, 'learning_rate': 0.029755227006292486, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:38,362] Trial 45 finished with value: 0.7781636238157977 and parameters: {'n_estimators': 131, 'learning_rate': 0.07344669559839026, 'max_depth': 3}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:39,148] Trial 46 finished with value: 0.7852782483217264 and parameters: {'n_estimators': 156, 'learning_rate': 0.018571772791125013, 'max_depth': 3}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:39,671] Trial 47 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 143, 'learning_rate': 0.023482652032341463, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:39,910] Trial 48 finished with value: 0.7813319530710835 and parameters: {'n_estimators': 103, 'learning_rate': 0.04413364484536917, 'max_depth': 1}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:40,393] Trial 49 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 135, 'learning_rate': 0.03354827782876521, 'max_depth': 2}. Best is trial 36 with value: 0.7892590501286152.\n",
      "[I 2024-12-02 16:32:40,394] A new study created in memory with name: no-name-0285c675-0e4d-4703-bc91-87c043e95ac3\n",
      "[I 2024-12-02 16:32:40,834] Trial 0 finished with value: 0.7742141916054959 and parameters: {'n_estimators': 64, 'learning_rate': 0.010087863532372551, 'max_depth': 4}. Best is trial 0 with value: 0.7742141916054959.\n",
      "[I 2024-12-02 16:32:42,106] Trial 1 finished with value: 0.7425152142543446 and parameters: {'n_estimators': 190, 'learning_rate': 0.20611687339036375, 'max_depth': 4}. Best is trial 0 with value: 0.7742141916054959.\n",
      "[I 2024-12-02 16:32:42,306] Trial 2 finished with value: 0.7749670619235836 and parameters: {'n_estimators': 86, 'learning_rate': 0.34408402344797107, 'max_depth': 1}. Best is trial 2 with value: 0.7749670619235836.\n",
      "[I 2024-12-02 16:32:42,923] Trial 3 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 122, 'learning_rate': 0.01658041448617889, 'max_depth': 3}. Best is trial 3 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 16:32:43,253] Trial 4 finished with value: 0.790824392998306 and parameters: {'n_estimators': 58, 'learning_rate': 0.06716859193254521, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:43,717] Trial 5 finished with value: 0.7543980174414957 and parameters: {'n_estimators': 131, 'learning_rate': 0.48608044823457336, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:44,037] Trial 6 finished with value: 0.7662682727900119 and parameters: {'n_estimators': 63, 'learning_rate': 0.29705476897981176, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:44,487] Trial 7 finished with value: 0.7781698977351151 and parameters: {'n_estimators': 128, 'learning_rate': 0.2077141714267112, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:46,010] Trial 8 finished with value: 0.775785808394504 and parameters: {'n_estimators': 170, 'learning_rate': 0.02458667848343819, 'max_depth': 5}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:47,117] Trial 9 finished with value: 0.7552073530334399 and parameters: {'n_estimators': 165, 'learning_rate': 0.10138079736044212, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:47,329] Trial 10 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 91, 'learning_rate': 0.04963520133486385, 'max_depth': 1}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:47,865] Trial 11 finished with value: 0.7876592007026788 and parameters: {'n_estimators': 104, 'learning_rate': 0.026327666106506116, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:48,054] Trial 12 finished with value: 0.7781604868561389 and parameters: {'n_estimators': 50, 'learning_rate': 0.01106263032677913, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:48,818] Trial 13 finished with value: 0.7409341865863605 and parameters: {'n_estimators': 146, 'learning_rate': 0.8897251506629156, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:49,748] Trial 14 finished with value: 0.768661773009599 and parameters: {'n_estimators': 104, 'learning_rate': 0.0709865307502539, 'max_depth': 5}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:50,044] Trial 15 finished with value: 0.7852876592007026 and parameters: {'n_estimators': 80, 'learning_rate': 0.030470758086300172, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:51,515] Trial 16 finished with value: 0.7583474496517975 and parameters: {'n_estimators': 200, 'learning_rate': 0.1144480631359582, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:52,064] Trial 17 finished with value: 0.7805288913984565 and parameters: {'n_estimators': 107, 'learning_rate': 0.04880768048065455, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:52,813] Trial 18 finished with value: 0.7876654746219962 and parameters: {'n_estimators': 148, 'learning_rate': 0.01666546264984076, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:53,639] Trial 19 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 118, 'learning_rate': 0.04183074142017782, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:53,906] Trial 20 finished with value: 0.7829067068197503 and parameters: {'n_estimators': 72, 'learning_rate': 0.016599557931441723, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:54,656] Trial 21 finished with value: 0.7860781730346946 and parameters: {'n_estimators': 148, 'learning_rate': 0.018631535854693047, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:55,391] Trial 22 finished with value: 0.7868686868686868 and parameters: {'n_estimators': 145, 'learning_rate': 0.018814957364020925, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:56,240] Trial 23 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 168, 'learning_rate': 0.01439756855955264, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:57,020] Trial 24 finished with value: 0.7789572746094485 and parameters: {'n_estimators': 156, 'learning_rate': 0.07255693064375286, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:57,656] Trial 25 finished with value: 0.78529393312002 and parameters: {'n_estimators': 179, 'learning_rate': 0.035084163921542025, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:58,568] Trial 26 finished with value: 0.7702647593951941 and parameters: {'n_estimators': 135, 'learning_rate': 0.07764057928697769, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:59,374] Trial 27 finished with value: 0.7591661961227179 and parameters: {'n_estimators': 119, 'learning_rate': 0.13491258765376682, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:32:59,729] Trial 28 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 97, 'learning_rate': 0.02297426091968823, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:00,208] Trial 29 finished with value: 0.7678743961352656 and parameters: {'n_estimators': 51, 'learning_rate': 0.010942750454810428, 'max_depth': 5}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:00,544] Trial 30 finished with value: 0.772620616098877 and parameters: {'n_estimators': 64, 'learning_rate': 0.010001879388939048, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:01,119] Trial 31 finished with value: 0.7829098437794089 and parameters: {'n_estimators': 113, 'learning_rate': 0.026801963104832762, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:01,626] Trial 32 finished with value: 0.7837003576134011 and parameters: {'n_estimators': 99, 'learning_rate': 0.0357450627279988, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:02,322] Trial 33 finished with value: 0.7829067068197503 and parameters: {'n_estimators': 137, 'learning_rate': 0.02206895338742384, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:03,168] Trial 34 finished with value: 0.7876717485413136 and parameters: {'n_estimators': 123, 'learning_rate': 0.014042695070717292, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:04,240] Trial 35 finished with value: 0.787668611581655 and parameters: {'n_estimators': 157, 'learning_rate': 0.013723080189362176, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:05,527] Trial 36 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 184, 'learning_rate': 0.01311989195027958, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:06,644] Trial 37 finished with value: 0.7425089403350273 and parameters: {'n_estimators': 123, 'learning_rate': 0.1625691535930515, 'max_depth': 5}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:07,742] Trial 38 finished with value: 0.78529393312002 and parameters: {'n_estimators': 160, 'learning_rate': 0.013748979243224433, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:08,323] Trial 39 finished with value: 0.7361816927034318 and parameters: {'n_estimators': 84, 'learning_rate': 0.29921227278610835, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:09,514] Trial 40 finished with value: 0.7742204655248133 and parameters: {'n_estimators': 177, 'learning_rate': 0.05719662840261646, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:10,508] Trial 41 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 141, 'learning_rate': 0.016641729755959594, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:11,934] Trial 42 finished with value: 0.7813256791517661 and parameters: {'n_estimators': 155, 'learning_rate': 0.013109605461909502, 'max_depth': 5}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:12,584] Trial 43 finished with value: 0.7868686868686868 and parameters: {'n_estimators': 127, 'learning_rate': 0.020433870281436794, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:13,368] Trial 44 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 154, 'learning_rate': 0.01560621838255884, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:13,670] Trial 45 finished with value: 0.7765480895915677 and parameters: {'n_estimators': 133, 'learning_rate': 0.2156402746423856, 'max_depth': 1}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:14,438] Trial 46 finished with value: 0.7329945416901938 and parameters: {'n_estimators': 112, 'learning_rate': 0.7955207586174152, 'max_depth': 4}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:15,282] Trial 47 finished with value: 0.7496329757199323 and parameters: {'n_estimators': 163, 'learning_rate': 0.4301355841396504, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:15,932] Trial 48 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 172, 'learning_rate': 0.028957178219577665, 'max_depth': 2}. Best is trial 4 with value: 0.790824392998306.\n",
      "[I 2024-12-02 16:33:16,333] Trial 49 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 77, 'learning_rate': 0.012018651416742932, 'max_depth': 3}. Best is trial 4 with value: 0.790824392998306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "Added 667 new labeled samples.\n",
      "--- Iteration 2 ---\n",
      "Added 271 new labeled samples.\n",
      "--- Iteration 3 ---\n",
      "Added 97 new labeled samples.\n",
      "--- Iteration 4 ---\n",
      "Added 25 new labeled samples.\n",
      "--- Iteration 5 ---\n",
      "Added 7 new labeled samples.\n",
      "--- Iteration 6 ---\n",
      "Added 6 new labeled samples.\n",
      "--- Iteration 7 ---\n",
      "Added 4 new labeled samples.\n",
      "--- Iteration 8 ---\n",
      "Added 1 new labeled samples.\n",
      "--- Iteration 9 ---\n",
      "Added 4 new labeled samples.\n",
      "--- Iteration 10 ---\n",
      "Added 1 new labeled samples.\n",
      "Final accuracy on test set: 0.6886\n"
     ]
    }
   ],
   "source": [
    "studyOne = optuna.create_study(direction='maximize')  \n",
    "studyOne.optimize(objective, n_trials=50)  \n",
    "best_paramsOne = studyOne.best_params\n",
    "clf1 = GradientBoostingClassifier(**best_paramsOne, random_state=0)\n",
    "\n",
    "studyTwo = optuna.create_study(direction='maximize')  \n",
    "studyTwo.optimize(objective, n_trials=50) \n",
    "best_paramsTwo = studyTwo.best_params\n",
    "clf2 = GradientBoostingClassifier(**best_paramsTwo, random_state=0)\n",
    "\n",
    "clf1.fit(X_labeled_view1, y_labeled)\n",
    "clf2.fit(X_labeled_view2, y_labeled)\n",
    "\n",
    "max_iterations = 10\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "X_unlabeled_view1 = X_unlabeled_view1.reset_index(drop=True)\n",
    "X_unlabeled_view2 = X_unlabeled_view2.reset_index(drop=True)\n",
    "\n",
    "# Co-training loop\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"--- Iteration {iteration + 1} ---\")\n",
    "    \n",
    "    # Step 1: Predict on the unlabeled data using both classifiers\n",
    "    probs1 = clf1.predict_proba(X_unlabeled_view1)\n",
    "    probs2 = clf2.predict_proba(X_unlabeled_view2)\n",
    "\n",
    "    # Step 2: Select confident predictions (probability > confidence_threshold)\n",
    "    confident_indices1 = np.where(np.max(probs1, axis=1) > confidence_threshold)[0]\n",
    "    confident_indices2 = np.where(np.max(probs2, axis=1) > confidence_threshold)[0]\n",
    "\n",
    "    # Ensure consistent indices by using `.iloc` only within bounds\n",
    "    if confident_indices1.size > 0:\n",
    "        confident_samples1_view1 = X_unlabeled_view1.iloc[confident_indices1]\n",
    "        confident_samples1_view2 = X_unlabeled_view2.iloc[confident_indices1]\n",
    "        confident_labels1 = clf1.predict(confident_samples1_view1)\n",
    "\n",
    "        X_labeled_view1 = pd.concat([X_labeled_view1, confident_samples1_view1], axis=0)\n",
    "        X_labeled_view2 = pd.concat([X_labeled_view2, confident_samples1_view2], axis=0)\n",
    "        y_labeled = np.hstack((y_labeled, confident_labels1))\n",
    "\n",
    "    if confident_indices2.size > 0:\n",
    "        confident_samples2_view1 = X_unlabeled_view1.iloc[confident_indices2]\n",
    "        confident_samples2_view2 = X_unlabeled_view2.iloc[confident_indices2]\n",
    "        confident_labels2 = clf2.predict(confident_samples2_view2)\n",
    "\n",
    "        X_labeled_view1 = pd.concat([X_labeled_view1, confident_samples2_view1], axis=0)\n",
    "        X_labeled_view2 = pd.concat([X_labeled_view2, confident_samples2_view2], axis=0)\n",
    "        y_labeled = np.hstack((y_labeled, confident_labels2))\n",
    "\n",
    "    # Step 3: Remove confident samples from the unlabeled set\n",
    "    confident_indices_combined = np.union1d(confident_indices1, confident_indices2)\n",
    "    X_unlabeled_view1 = X_unlabeled_view1.drop(index=confident_indices_combined).reset_index(drop=True)\n",
    "    X_unlabeled_view2 = X_unlabeled_view2.drop(index=confident_indices_combined).reset_index(drop=True)\n",
    "\n",
    "    # Retrain classifiers on the updated labeled set\n",
    "    clf1.fit(X_labeled_view1, y_labeled)\n",
    "    clf2.fit(X_labeled_view2, y_labeled)\n",
    "\n",
    "    # Step 4: Stop if no confident predictions\n",
    "    if confident_indices1.size == 0 and confident_indices2.size == 0:\n",
    "        print(\"No more confident predictions; stopping training.\")\n",
    "        break\n",
    "\n",
    "    print(f\"Added {len(confident_indices1) + len(confident_indices2)} new labeled samples.\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "probs1_test = clf1.predict_proba(X_mushroom_test.iloc[:, :num_features // 2])  # First view\n",
    "probs2_test = clf2.predict_proba(X_mushroom_test.iloc[:, num_features // 2:])  # Second view\n",
    "\n",
    "# Average the probabilities from both classifiers\n",
    "avg_probs_test = (probs1_test + probs2_test) / 2\n",
    "\n",
    "# Convert averaged probabilities to predicted labels\n",
    "final_predictions = np.argmax(avg_probs_test, axis=1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_mushroom_test, final_predictions)\n",
    "print(f\"Final accuracy on test set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(\n",
    "    X_mushroom_train, y_mushroom_train, test_size=0.9, stratify=y_mushroom_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class SemiBoost(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10, beta=1.0):\n",
    "        self.base_estimator = base_estimator or DecisionTreeClassifier(max_depth=1)\n",
    "        self.n_estimators = n_estimators\n",
    "        self.beta = beta\n",
    "\n",
    "    def fit(self, X_labeled, y_labeled, X_unlabeled):\n",
    "        X_labeled, y_labeled = check_X_y(X_labeled, y_labeled)\n",
    "        X_unlabeled = check_array(X_unlabeled)\n",
    "\n",
    "        self.classes_ = np.unique(y_labeled)\n",
    "        n_labeled = X_labeled.shape[0]\n",
    "        n_unlabeled = X_unlabeled.shape[0]\n",
    "\n",
    "        X_combined = np.vstack((X_labeled, X_unlabeled))\n",
    "        y_combined = np.hstack((y_labeled, [-1] * n_unlabeled))\n",
    "\n",
    "        weights = np.ones(n_labeled + n_unlabeled) / (n_labeled + n_unlabeled)\n",
    "\n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            clf = self.base_estimator\n",
    "            clf.fit(X_combined, y_combined, sample_weight=weights)\n",
    "\n",
    "            y_pred = clf.predict(X_combined)\n",
    "\n",
    "            labeled_error = np.sum(weights[:n_labeled] * (y_pred[:n_labeled] != y_labeled)) / np.sum(weights[:n_labeled])\n",
    "\n",
    "            weights[:n_labeled] *= np.exp(self.beta * (y_pred[:n_labeled] != y_labeled))\n",
    "\n",
    "            confident_predictions = np.abs(clf.predict_proba(X_unlabeled).max(axis=1) - 0.5) > 0.3\n",
    "            pseudo_labels = clf.predict(X_unlabeled)\n",
    "            weights[n_labeled:] *= np.exp(self.beta * confident_predictions * (pseudo_labels != y_combined[n_labeled:]))\n",
    "\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            self.estimators_.append(clf)\n",
    "            self.estimator_weights_.append(np.log(1 / labeled_error))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "\n",
    "        final_prediction = np.zeros(X.shape[0])\n",
    "        for weight, clf in zip(self.estimator_weights_, self.estimators_):\n",
    "            final_prediction += weight * clf.predict(X)\n",
    "\n",
    "        return np.sign(final_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "semi_boost = SemiBoost(n_estimators=10)\n",
    "semi_boost.fit(X_labeled, y_labeled, X_unlabeled)\n",
    "\n",
    "\n",
    "y_pred = semi_boost.predict(X_mushroom_test)\n",
    "accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7223\n",
      "Precision: 0.6505, Recall: 0.5284, F1-score: 0.5831\n",
      "AUC: 0.7623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# Train an autoencoder using MLPRegressor\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(50, 25, 50), max_iter=500, random_state=42)\n",
    "autoencoder.fit(X_unlabeled, X_unlabeled)\n",
    "\n",
    "# Extract encoded features\n",
    "encoder = autoencoder\n",
    "X_labeled_encoded = encoder.predict(X_labeled)\n",
    "X_unlabeled_encoded = encoder.predict(X_unlabeled)\n",
    "X_test_encoded = encoder.predict(X_mushroom_test)\n",
    "\n",
    "# Train a classifier on the labeled data with encoded features\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_labeled_encoded, y_labeled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_mushroom_test, y_pred, average=\"binary\")\n",
    "auc = roc_auc_score(y_mushroom_test, clf.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important: we will reuse X_mushroom_train, X_mushroom_test, y_mushroom_train, y_mushroom_test for final evaluation\n",
    "# split the dataset into labeled and unlabeled data, we will use 10/90, 20/80, 30/70, 40/60, 50/50 splits, use num_samples for the total number of samples\n",
    "\n",
    "# all four models redefined:\n",
    "\n",
    "def self_training_gradient_boosting(y_mushroom_train_unlabeled, split_ratio):\n",
    "    self_training_model = SelfTrainingClassifier(GradientBoostingClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=0))\n",
    "    self_training_model.fit(X_mushroom_train, y_mushroom_train_unlabeled)\n",
    "\n",
    "    # Train the self-training model and evaluate its performance\n",
    "    y_pred = self_training_model.predict(X_mushroom_test)\n",
    "    accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "    labeled_percentage = int((1 - split_ratio) * 100)\n",
    "    unlabeled_percentage = int(split_ratio * 100)\n",
    "\n",
    "    print(f\"Accuracy of Self-Training with Gradient Boosting with a split ratio of {unlabeled_percentage}%/{labeled_percentage}%: {accuracy:.2f}\")\n",
    "\n",
    "    # return the precision, recall, F1-score, and area under the ROC curve (AUC).\n",
    "\n",
    "def co_training_gradient_boosting(X_labeled, X_unlabeled, y_labeled, split_ratio):\n",
    "    \n",
    "    num_features = X_labeled.shape[1]\n",
    "    X_labeled_view1, X_labeled_view2 = X_labeled.iloc[:, :num_features // 2], X_labeled.iloc[:, num_features // 2:]\n",
    "    X_unlabeled_view1, X_unlabeled_view2 = X_unlabeled.iloc[:, :num_features // 2], X_unlabeled.iloc[:, num_features // 2:]\n",
    "\n",
    "    studyOne = optuna.create_study(direction='maximize')  \n",
    "    studyOne.optimize(objective, n_trials=50)  \n",
    "    best_paramsOne = studyOne.best_params\n",
    "    clf1 = GradientBoostingClassifier(**best_paramsOne, random_state=0)\n",
    "\n",
    "    studyTwo = optuna.create_study(direction='maximize')  \n",
    "    studyTwo.optimize(objective, n_trials=50) \n",
    "    best_paramsTwo = studyTwo.best_params\n",
    "    clf2 = GradientBoostingClassifier(**best_paramsTwo, random_state=0)\n",
    "\n",
    "    clf1.fit(X_labeled_view1, y_labeled)\n",
    "    clf2.fit(X_labeled_view2, y_labeled)\n",
    "\n",
    "    max_iterations = 10\n",
    "    confidence_threshold = 0.9\n",
    "\n",
    "    X_unlabeled_view1 = X_unlabeled_view1.reset_index(drop=True)\n",
    "    X_unlabeled_view2 = X_unlabeled_view2.reset_index(drop=True)\n",
    "\n",
    "    # Co-training loop\n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"--- Iteration {iteration + 1} ---\")\n",
    "        \n",
    "        # Step 1: Predict on the unlabeled data using both classifiers\n",
    "        probs1 = clf1.predict_proba(X_unlabeled_view1)\n",
    "        probs2 = clf2.predict_proba(X_unlabeled_view2)\n",
    "\n",
    "        # Step 2: Select confident predictions (probability > confidence_threshold)\n",
    "        confident_indices1 = np.where(np.max(probs1, axis=1) > confidence_threshold)[0]\n",
    "        confident_indices2 = np.where(np.max(probs2, axis=1) > confidence_threshold)[0]\n",
    "\n",
    "        # Ensure consistent indices by using `.iloc` only within bounds\n",
    "        if confident_indices1.size > 0:\n",
    "            confident_samples1_view1 = X_unlabeled_view1.iloc[confident_indices1]\n",
    "            confident_samples1_view2 = X_unlabeled_view2.iloc[confident_indices1]\n",
    "            confident_labels1 = clf1.predict(confident_samples1_view1)\n",
    "\n",
    "            X_labeled_view1 = pd.concat([X_labeled_view1, confident_samples1_view1], axis=0)\n",
    "            X_labeled_view2 = pd.concat([X_labeled_view2, confident_samples1_view2], axis=0)\n",
    "            y_labeled = np.hstack((y_labeled, confident_labels1))\n",
    "\n",
    "        if confident_indices2.size > 0:\n",
    "            confident_samples2_view1 = X_unlabeled_view1.iloc[confident_indices2]\n",
    "            confident_samples2_view2 = X_unlabeled_view2.iloc[confident_indices2]\n",
    "            confident_labels2 = clf2.predict(confident_samples2_view2)\n",
    "\n",
    "            X_labeled_view1 = pd.concat([X_labeled_view1, confident_samples2_view1], axis=0)\n",
    "            X_labeled_view2 = pd.concat([X_labeled_view2, confident_samples2_view2], axis=0)\n",
    "            y_labeled = np.hstack((y_labeled, confident_labels2))\n",
    "\n",
    "        # Step 3: Remove confident samples from the unlabeled set\n",
    "        confident_indices_combined = np.union1d(confident_indices1, confident_indices2)\n",
    "        X_unlabeled_view1 = X_unlabeled_view1.drop(index=confident_indices_combined).reset_index(drop=True)\n",
    "        X_unlabeled_view2 = X_unlabeled_view2.drop(index=confident_indices_combined).reset_index(drop=True)\n",
    "\n",
    "        # Retrain classifiers on the updated labeled set\n",
    "        clf1.fit(X_labeled_view1, y_labeled)\n",
    "        clf2.fit(X_labeled_view2, y_labeled)\n",
    "\n",
    "        # Step 4: Stop if no confident predictions\n",
    "        if confident_indices1.size == 0 and confident_indices2.size == 0:\n",
    "            print(\"No more confident predictions; stopping training.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Added {len(confident_indices1) + len(confident_indices2)} new labeled samples.\")\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    probs1_test = clf1.predict_proba(X_mushroom_test.iloc[:, :num_features // 2])  # First view\n",
    "    probs2_test = clf2.predict_proba(X_mushroom_test.iloc[:, num_features // 2:])  # Second view\n",
    "\n",
    "    # Average the probabilities from both classifiers\n",
    "    avg_probs_test = (probs1_test + probs2_test) / 2\n",
    "\n",
    "    # Convert averaged probabilities to predicted labels\n",
    "    final_predictions = np.argmax(avg_probs_test, axis=1)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_mushroom_test, final_predictions)\n",
    "    labeled_percentage = int((1 - split_ratio) * 100)\n",
    "    unlabeled_percentage = int(split_ratio * 100)\n",
    "    \n",
    "    print(f\"Accuracy on test set of co-training with Gradient Boosting with a split ratio of {unlabeled_percentage}%/{labeled_percentage}%: {accuracy:.4f}\")\n",
    "\n",
    "def semi_supervised_ensemble(X_labeled, X_unlabeled, y_labeled, split_ratio):\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_labeled, y_labeled, test_size=0.9, stratify=y_labeled)\n",
    "    \n",
    "    semi_boost = SemiBoost(n_estimators=10)\n",
    "    semi_boost.fit(X_labeled, y_labeled, X_unlabeled)\n",
    "\n",
    "    y_pred = semi_boost.predict(X_mushroom_test)\n",
    "    accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "    labeled_percentage = int((1 - split_ratio) * 100)\n",
    "    unlabeled_percentage = int(split_ratio * 100)\n",
    "\n",
    "    print(f\"Accuracy of semi-supervised ensemble with a split ratio of {unlabeled_percentage}%/{labeled_percentage}%: {accuracy:.2f}\")\n",
    "\n",
    "def unsupervised_pretraining(X_labeled, X_unlabeled, y_labeled, split_ratio):\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_labeled, y_labeled, test_size=0.9, stratify=y_labeled)\n",
    "\n",
    "    # Train an autoencoder using MLPRegressor\n",
    "    autoencoder = MLPRegressor(hidden_layer_sizes=(50, 25, 50), max_iter=500, random_state=42)\n",
    "    autoencoder.fit(X_unlabeled, X_unlabeled)\n",
    "\n",
    "    # Extract encoded features\n",
    "    encoder = autoencoder\n",
    "    X_labeled_encoded = encoder.predict(X_labeled)\n",
    "    X_unlabeled_encoded = encoder.predict(X_unlabeled)\n",
    "    X_test_encoded = encoder.predict(X_mushroom_test)\n",
    "\n",
    "    # Train a classifier on the labeled data with encoded features\n",
    "    clf = GradientBoostingClassifier(random_state=42)\n",
    "    clf.fit(X_labeled_encoded, y_labeled)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = clf.predict(X_test_encoded)\n",
    "    accuracy = accuracy_score(y_mushroom_test, y_pred)\n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(y_mushroom_test, y_pred)\n",
    "    # auc = roc_auc_score(y_mushroom_test, clf.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "    labeled_percentage = int((1 - split_ratio) * 100)\n",
    "    unlabeled_percentage = int(split_ratio * 100)\n",
    "\n",
    "    print(f\"Accuracy of unsupservised pretraining with a split ratio of {unlabeled_percentage}%/{labeled_percentage}%: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    # print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:15:55,829] A new study created in memory with name: no-name-0401a311-e02a-47d9-9b74-2f5cc95ecfa3\n",
      "[I 2024-12-02 18:15:56,484] Trial 0 finished with value: 0.7662714097496706 and parameters: {'n_estimators': 176, 'learning_rate': 0.23574859068968446, 'max_depth': 2}. Best is trial 0 with value: 0.7662714097496706.\n",
      "[I 2024-12-02 18:15:56,795] Trial 1 finished with value: 0.7678430265386786 and parameters: {'n_estimators': 138, 'learning_rate': 0.5794448218962946, 'max_depth': 1}. Best is trial 1 with value: 0.7678430265386786.\n",
      "[I 2024-12-02 18:15:57,554] Trial 2 finished with value: 0.7837034945730597 and parameters: {'n_estimators': 153, 'learning_rate': 0.03099305753081659, 'max_depth': 3}. Best is trial 2 with value: 0.7837034945730597.\n",
      "[I 2024-12-02 18:15:57,915] Trial 3 finished with value: 0.7741859589685676 and parameters: {'n_estimators': 70, 'learning_rate': 0.11286948031163493, 'max_depth': 3}. Best is trial 2 with value: 0.7837034945730597.\n",
      "[I 2024-12-02 18:15:58,129] Trial 4 finished with value: 0.7789447267708137 and parameters: {'n_estimators': 95, 'learning_rate': 0.14307681405156952, 'max_depth': 1}. Best is trial 2 with value: 0.7837034945730597.\n",
      "[I 2024-12-02 18:15:58,425] Trial 5 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 82, 'learning_rate': 0.197877091535557, 'max_depth': 2}. Best is trial 2 with value: 0.7837034945730597.\n",
      "[I 2024-12-02 18:15:58,871] Trial 6 finished with value: 0.7512359621055273 and parameters: {'n_estimators': 119, 'learning_rate': 0.686478092380064, 'max_depth': 2}. Best is trial 2 with value: 0.7837034945730597.\n",
      "[I 2024-12-02 18:15:59,798] Trial 7 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 102, 'learning_rate': 0.013475048861787227, 'max_depth': 5}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:00,093] Trial 8 finished with value: 0.7789447267708136 and parameters: {'n_estimators': 133, 'learning_rate': 0.020536272231465452, 'max_depth': 1}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:01,072] Trial 9 finished with value: 0.747261434217956 and parameters: {'n_estimators': 148, 'learning_rate': 0.2539380762634216, 'max_depth': 4}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:01,585] Trial 10 finished with value: 0.7694585607629085 and parameters: {'n_estimators': 56, 'learning_rate': 0.010549728184385694, 'max_depth': 5}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:03,279] Trial 11 finished with value: 0.7694460129242738 and parameters: {'n_estimators': 193, 'learning_rate': 0.037998940387453, 'max_depth': 5}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:04,007] Trial 12 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 103, 'learning_rate': 0.041841562468056905, 'max_depth': 4}. Best is trial 7 with value: 0.7844940084070519.\n",
      "[I 2024-12-02 18:16:05,078] Trial 13 finished with value: 0.7860907208733294 and parameters: {'n_estimators': 158, 'learning_rate': 0.011613886687906212, 'max_depth': 4}. Best is trial 13 with value: 0.7860907208733294.\n",
      "[I 2024-12-02 18:16:06,209] Trial 14 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 167, 'learning_rate': 0.010830472826774238, 'max_depth': 4}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:07,332] Trial 15 finished with value: 0.7718395131438609 and parameters: {'n_estimators': 169, 'learning_rate': 0.06911665707189209, 'max_depth': 4}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:08,666] Trial 16 finished with value: 0.7789541376497897 and parameters: {'n_estimators': 198, 'learning_rate': 0.019709938079981944, 'max_depth': 4}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:09,540] Trial 17 finished with value: 0.7781604868561389 and parameters: {'n_estimators': 170, 'learning_rate': 0.06505950690813556, 'max_depth': 3}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:10,599] Trial 18 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 157, 'learning_rate': 0.017043383261774375, 'max_depth': 4}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:12,261] Trial 19 finished with value: 0.7797383775644645 and parameters: {'n_estimators': 184, 'learning_rate': 0.010069879752932383, 'max_depth': 5}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:12,877] Trial 20 finished with value: 0.784490871447393 and parameters: {'n_estimators': 121, 'learning_rate': 0.02457325231861563, 'max_depth': 3}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:13,867] Trial 21 finished with value: 0.7837034945730597 and parameters: {'n_estimators': 109, 'learning_rate': 0.01358251070465506, 'max_depth': 5}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:15,216] Trial 22 finished with value: 0.7789478637304723 and parameters: {'n_estimators': 142, 'learning_rate': 0.014528484286798997, 'max_depth': 5}. Best is trial 14 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:16,370] Trial 23 finished with value: 0.7876748855009724 and parameters: {'n_estimators': 162, 'learning_rate': 0.010011110625293227, 'max_depth': 4}. Best is trial 23 with value: 0.7876748855009724.\n",
      "[I 2024-12-02 18:16:17,463] Trial 24 finished with value: 0.7829192546583851 and parameters: {'n_estimators': 162, 'learning_rate': 0.02760692410165996, 'max_depth': 4}. Best is trial 23 with value: 0.7876748855009724.\n",
      "[I 2024-12-02 18:16:18,680] Trial 25 finished with value: 0.7694554238032498 and parameters: {'n_estimators': 181, 'learning_rate': 0.0570809581216803, 'max_depth': 4}. Best is trial 23 with value: 0.7876748855009724.\n",
      "[I 2024-12-02 18:16:19,686] Trial 26 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 164, 'learning_rate': 0.010412282482847344, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:20,658] Trial 27 finished with value: 0.7852813852813852 and parameters: {'n_estimators': 185, 'learning_rate': 0.021241643529799792, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:21,358] Trial 28 finished with value: 0.7520358868184955 and parameters: {'n_estimators': 130, 'learning_rate': 0.42496429075978975, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:21,993] Trial 29 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 174, 'learning_rate': 0.016364987325419657, 'max_depth': 2}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:22,733] Trial 30 finished with value: 0.7837034945730597 and parameters: {'n_estimators': 147, 'learning_rate': 0.037396207898172176, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:23,904] Trial 31 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 166, 'learning_rate': 0.010438994028186469, 'max_depth': 4}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:25,012] Trial 32 finished with value: 0.7900495639626074 and parameters: {'n_estimators': 157, 'learning_rate': 0.013064943015187758, 'max_depth': 4}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:25,846] Trial 33 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 153, 'learning_rate': 0.016240590743102048, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:26,957] Trial 34 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 143, 'learning_rate': 0.028696775213965492, 'max_depth': 4}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:27,963] Trial 35 finished with value: 0.7868718238283454 and parameters: {'n_estimators': 190, 'learning_rate': 0.013302209389823658, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:29,158] Trial 36 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 175, 'learning_rate': 0.023142082355626134, 'max_depth': 4}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:29,654] Trial 37 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 136, 'learning_rate': 0.010054134016853535, 'max_depth': 2}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:30,531] Trial 38 finished with value: 0.7757889453541628 and parameters: {'n_estimators': 164, 'learning_rate': 0.08635544255825962, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:31,740] Trial 39 finished with value: 0.7290388355605747 and parameters: {'n_estimators': 178, 'learning_rate': 0.9013814359573012, 'max_depth': 4}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:32,302] Trial 40 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 153, 'learning_rate': 0.018175427054948384, 'max_depth': 2}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:33,326] Trial 41 finished with value: 0.7876654746219962 and parameters: {'n_estimators': 194, 'learning_rate': 0.012933378408029326, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:34,436] Trial 42 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 191, 'learning_rate': 0.01332229511726983, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:35,496] Trial 43 finished with value: 0.7852813852813852 and parameters: {'n_estimators': 196, 'learning_rate': 0.014527796681816406, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:36,248] Trial 44 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 200, 'learning_rate': 0.012528781047595031, 'max_depth': 2}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:37,226] Trial 45 finished with value: 0.7765731852688373 and parameters: {'n_estimators': 187, 'learning_rate': 0.03305672067582775, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:38,189] Trial 46 finished with value: 0.7662714097496706 and parameters: {'n_estimators': 191, 'learning_rate': 0.16237576746625948, 'max_depth': 3}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:38,593] Trial 47 finished with value: 0.7789478637304723 and parameters: {'n_estimators': 178, 'learning_rate': 0.01937329636164942, 'max_depth': 1}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:39,168] Trial 48 finished with value: 0.778160486856139 and parameters: {'n_estimators': 159, 'learning_rate': 0.26044517202073936, 'max_depth': 2}. Best is trial 26 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:16:39,814] Trial 49 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 126, 'learning_rate': 0.012918384098934942, 'max_depth': 3}. Best is trial 49 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:16:39,815] A new study created in memory with name: no-name-2ecf039e-3c52-4db2-8021-352de50215df\n",
      "[I 2024-12-02 18:16:40,042] Trial 0 finished with value: 0.7607127172344563 and parameters: {'n_estimators': 98, 'learning_rate': 0.904215577723585, 'max_depth': 1}. Best is trial 0 with value: 0.7607127172344563.\n",
      "[I 2024-12-02 18:16:40,366] Trial 1 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 58, 'learning_rate': 0.01830145276387711, 'max_depth': 3}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:41,217] Trial 2 finished with value: 0.7758140410314323 and parameters: {'n_estimators': 126, 'learning_rate': 0.07526359006594203, 'max_depth': 4}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:41,633] Trial 3 finished with value: 0.7805383022774327 and parameters: {'n_estimators': 185, 'learning_rate': 0.04657968124862189, 'max_depth': 1}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:42,108] Trial 4 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 183, 'learning_rate': 0.02766088762391126, 'max_depth': 1}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:42,440] Trial 5 finished with value: 0.7805320283581153 and parameters: {'n_estimators': 145, 'learning_rate': 0.10123817338621988, 'max_depth': 1}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:42,713] Trial 6 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 119, 'learning_rate': 0.05859974830766722, 'max_depth': 1}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:43,206] Trial 7 finished with value: 0.7694679716418846 and parameters: {'n_estimators': 53, 'learning_rate': 0.16693339762183593, 'max_depth': 5}. Best is trial 1 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:16:43,798] Trial 8 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 83, 'learning_rate': 0.020027798265668785, 'max_depth': 4}. Best is trial 8 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 18:16:43,977] Trial 9 finished with value: 0.7741985068072024 and parameters: {'n_estimators': 74, 'learning_rate': 0.029374925587885608, 'max_depth': 1}. Best is trial 8 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 18:16:44,447] Trial 10 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 88, 'learning_rate': 0.011814650261005697, 'max_depth': 3}. Best is trial 8 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 18:16:44,879] Trial 11 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 83, 'learning_rate': 0.011302486223847419, 'max_depth': 3}. Best is trial 8 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 18:16:45,575] Trial 12 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 100, 'learning_rate': 0.016742083813861455, 'max_depth': 4}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:46,319] Trial 13 finished with value: 0.75520735303344 and parameters: {'n_estimators': 108, 'learning_rate': 0.21565016070618018, 'max_depth': 4}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:47,658] Trial 14 finished with value: 0.7734079929732104 and parameters: {'n_estimators': 145, 'learning_rate': 0.02493783193507827, 'max_depth': 5}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:48,181] Trial 15 finished with value: 0.7773762469414643 and parameters: {'n_estimators': 71, 'learning_rate': 0.010408187392793878, 'max_depth': 4}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:49,227] Trial 16 finished with value: 0.7377470355731226 and parameters: {'n_estimators': 134, 'learning_rate': 0.3927572214615169, 'max_depth': 4}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:49,617] Trial 17 finished with value: 0.7860875839136708 and parameters: {'n_estimators': 105, 'learning_rate': 0.0442454631853084, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:50,247] Trial 18 finished with value: 0.7837160424116945 and parameters: {'n_estimators': 164, 'learning_rate': 0.04230065180863328, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:50,730] Trial 19 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 105, 'learning_rate': 0.11092315328722611, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:51,155] Trial 20 finished with value: 0.7860938578329882 and parameters: {'n_estimators': 111, 'learning_rate': 0.041055888227523006, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:51,605] Trial 21 finished with value: 0.7853033439989962 and parameters: {'n_estimators': 115, 'learning_rate': 0.03656627636257479, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:51,967] Trial 22 finished with value: 0.7860969947926469 and parameters: {'n_estimators': 94, 'learning_rate': 0.05908958841178289, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:52,311] Trial 23 finished with value: 0.7829223916180437 and parameters: {'n_estimators': 94, 'learning_rate': 0.07000246047727315, 'max_depth': 2}. Best is trial 12 with value: 0.7868812347073216.\n",
      "[I 2024-12-02 18:16:52,977] Trial 24 finished with value: 0.792417968504925 and parameters: {'n_estimators': 130, 'learning_rate': 0.016874997145731215, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:53,700] Trial 25 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 138, 'learning_rate': 0.01712228531191519, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:54,534] Trial 26 finished with value: 0.7868686868686868 and parameters: {'n_estimators': 162, 'learning_rate': 0.016635302869832058, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:55,223] Trial 27 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 135, 'learning_rate': 0.015016758117698523, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:55,997] Trial 28 finished with value: 0.79004329004329 and parameters: {'n_estimators': 153, 'learning_rate': 0.014740264632352784, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:56,819] Trial 29 finished with value: 0.7488393249262815 and parameters: {'n_estimators': 163, 'learning_rate': 0.42887415539673734, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:57,807] Trial 30 finished with value: 0.7480456741326307 and parameters: {'n_estimators': 197, 'learning_rate': 0.7078965357015413, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:58,539] Trial 31 finished with value: 0.7900401530836312 and parameters: {'n_estimators': 144, 'learning_rate': 0.014595111888046883, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:59,300] Trial 32 finished with value: 0.7852845222410438 and parameters: {'n_estimators': 150, 'learning_rate': 0.022680319472525533, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:16:59,958] Trial 33 finished with value: 0.79004329004329 and parameters: {'n_estimators': 128, 'learning_rate': 0.014994711462202801, 'max_depth': 3}. Best is trial 24 with value: 0.792417968504925.\n",
      "[I 2024-12-02 18:17:00,597] Trial 34 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 125, 'learning_rate': 0.014289234697338877, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:01,643] Trial 35 finished with value: 0.7837034945730597 and parameters: {'n_estimators': 154, 'learning_rate': 0.03135921068724778, 'max_depth': 4}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:02,304] Trial 36 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 129, 'learning_rate': 0.013231094505295362, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:03,196] Trial 37 finished with value: 0.7837129054520359 and parameters: {'n_estimators': 125, 'learning_rate': 0.010213323299526844, 'max_depth': 4}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:03,816] Trial 38 finished with value: 0.7829004329004329 and parameters: {'n_estimators': 119, 'learning_rate': 0.02495916078394383, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:04,701] Trial 39 finished with value: 0.786075036075036 and parameters: {'n_estimators': 175, 'learning_rate': 0.020744786883600198, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:05,589] Trial 40 finished with value: 0.7876717485413136 and parameters: {'n_estimators': 129, 'learning_rate': 0.012694470685880225, 'max_depth': 4}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:06,226] Trial 41 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 125, 'learning_rate': 0.013402241855113475, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:06,914] Trial 42 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 121, 'learning_rate': 0.019612083937635173, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:07,623] Trial 43 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 139, 'learning_rate': 0.012047646949927953, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:08,128] Trial 44 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 140, 'learning_rate': 0.012669669640188426, 'max_depth': 2}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:08,787] Trial 45 finished with value: 0.784490871447393 and parameters: {'n_estimators': 130, 'learning_rate': 0.030305794104409492, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:09,364] Trial 46 finished with value: 0.79004329004329 and parameters: {'n_estimators': 113, 'learning_rate': 0.01209320050874462, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:10,198] Trial 47 finished with value: 0.78529393312002 and parameters: {'n_estimators': 121, 'learning_rate': 0.010094085749453623, 'max_depth': 4}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:10,880] Trial 48 finished with value: 0.7852813852813852 and parameters: {'n_estimators': 134, 'learning_rate': 0.020379139636518488, 'max_depth': 3}. Best is trial 34 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:17:11,880] Trial 49 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 147, 'learning_rate': 0.025408489075256682, 'max_depth': 4}. Best is trial 34 with value: 0.7924211054645836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "Added 6 new labeled samples.\n",
      "--- Iteration 2 ---\n",
      "Added 20 new labeled samples.\n",
      "--- Iteration 3 ---\n",
      "Added 18 new labeled samples.\n",
      "--- Iteration 4 ---\n",
      "Added 51 new labeled samples.\n",
      "--- Iteration 5 ---\n",
      "Added 62 new labeled samples.\n",
      "--- Iteration 6 ---\n",
      "Added 266 new labeled samples.\n",
      "--- Iteration 7 ---\n",
      "Added 449 new labeled samples.\n",
      "--- Iteration 8 ---\n",
      "Added 266 new labeled samples.\n",
      "--- Iteration 9 ---\n",
      "Added 129 new labeled samples.\n",
      "--- Iteration 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:17:13,280] A new study created in memory with name: no-name-cddd3662-a999-4215-b18d-94cee35ef969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 42 new labeled samples.\n",
      "Accuracy on test set of co-training with Gradient Boosting with a split ratio of 10%/90%: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:17:13,876] Trial 0 finished with value: 0.7821130560260995 and parameters: {'n_estimators': 167, 'learning_rate': 0.05856245320872076, 'max_depth': 2}. Best is trial 0 with value: 0.7821130560260995.\n",
      "[I 2024-12-02 18:17:14,162] Trial 1 finished with value: 0.7733954451345755 and parameters: {'n_estimators': 79, 'learning_rate': 0.15230924209910532, 'max_depth': 2}. Best is trial 0 with value: 0.7821130560260995.\n",
      "[I 2024-12-02 18:17:14,665] Trial 2 finished with value: 0.7472677081372734 and parameters: {'n_estimators': 70, 'learning_rate': 0.37059267397343426, 'max_depth': 4}. Best is trial 0 with value: 0.7821130560260995.\n",
      "[I 2024-12-02 18:17:14,935] Trial 3 finished with value: 0.7868686868686868 and parameters: {'n_estimators': 52, 'learning_rate': 0.07483848102462487, 'max_depth': 3}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:15,603] Trial 4 finished with value: 0.7773668360624881 and parameters: {'n_estimators': 126, 'learning_rate': 0.0583186585484482, 'max_depth': 3}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:16,766] Trial 5 finished with value: 0.7543886065625196 and parameters: {'n_estimators': 124, 'learning_rate': 0.47235195862728185, 'max_depth': 5}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:17,340] Trial 6 finished with value: 0.7456772695903131 and parameters: {'n_estimators': 63, 'learning_rate': 0.42126624538427837, 'max_depth': 5}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:17,741] Trial 7 finished with value: 0.7638810464897421 and parameters: {'n_estimators': 181, 'learning_rate': 0.5595436696952341, 'max_depth': 1}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:19,013] Trial 8 finished with value: 0.7440836940836941 and parameters: {'n_estimators': 180, 'learning_rate': 0.5965991172623218, 'max_depth': 4}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:19,745] Trial 9 finished with value: 0.7852782483217264 and parameters: {'n_estimators': 144, 'learning_rate': 0.0285059299505201, 'max_depth': 3}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:19,973] Trial 10 finished with value: 0.7678649852562895 and parameters: {'n_estimators': 96, 'learning_rate': 0.010868370226401823, 'max_depth': 1}. Best is trial 3 with value: 0.7868686868686868.\n",
      "[I 2024-12-02 18:17:20,706] Trial 11 finished with value: 0.7868718238283454 and parameters: {'n_estimators': 142, 'learning_rate': 0.0178245884681693, 'max_depth': 3}. Best is trial 11 with value: 0.7868718238283454.\n",
      "[I 2024-12-02 18:17:21,110] Trial 12 finished with value: 0.7789510006901311 and parameters: {'n_estimators': 106, 'learning_rate': 0.010369536109515094, 'max_depth': 2}. Best is trial 11 with value: 0.7868718238283454.\n",
      "[I 2024-12-02 18:17:21,468] Trial 13 finished with value: 0.7884622623753058 and parameters: {'n_estimators': 50, 'learning_rate': 0.029032424128151383, 'max_depth': 4}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:22,571] Trial 14 finished with value: 0.7813319530710835 and parameters: {'n_estimators': 156, 'learning_rate': 0.024633859221433258, 'max_depth': 4}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:24,120] Trial 15 finished with value: 0.7781667607754563 and parameters: {'n_estimators': 200, 'learning_rate': 0.024174220801174283, 'max_depth': 4}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:25,415] Trial 16 finished with value: 0.7559759081498212 and parameters: {'n_estimators': 139, 'learning_rate': 0.1625865237073116, 'max_depth': 5}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:26,093] Trial 17 finished with value: 0.7852970700796786 and parameters: {'n_estimators': 96, 'learning_rate': 0.015977152124978532, 'max_depth': 4}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:26,696] Trial 18 finished with value: 0.7781542129368215 and parameters: {'n_estimators': 118, 'learning_rate': 0.04631735015472754, 'max_depth': 3}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:27,147] Trial 19 finished with value: 0.7836972206537423 and parameters: {'n_estimators': 84, 'learning_rate': 0.036312560706261654, 'max_depth': 3}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:27,349] Trial 20 finished with value: 0.7773699730221469 and parameters: {'n_estimators': 50, 'learning_rate': 0.017324705438984636, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:27,628] Trial 21 finished with value: 0.7797415145241231 and parameters: {'n_estimators': 52, 'learning_rate': 0.08712648377399959, 'max_depth': 3}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:28,078] Trial 22 finished with value: 0.7757920823138214 and parameters: {'n_estimators': 63, 'learning_rate': 0.09600777403442505, 'max_depth': 4}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:28,507] Trial 23 finished with value: 0.7734299516908212 and parameters: {'n_estimators': 77, 'learning_rate': 0.2135978032023042, 'max_depth': 3}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:29,010] Trial 24 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 137, 'learning_rate': 0.015778027900388358, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:29,527] Trial 25 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 140, 'learning_rate': 0.014737659294895783, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:29,886] Trial 26 finished with value: 0.7749858836815358 and parameters: {'n_estimators': 153, 'learning_rate': 0.013753889664136735, 'max_depth': 1}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:30,378] Trial 27 finished with value: 0.7393343371604241 and parameters: {'n_estimators': 132, 'learning_rate': 0.9338045697997884, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:30,805] Trial 28 finished with value: 0.7860875839136708 and parameters: {'n_estimators': 113, 'learning_rate': 0.03591427414383236, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:31,198] Trial 29 finished with value: 0.7805351653177739 and parameters: {'n_estimators': 167, 'learning_rate': 0.02123328569960746, 'max_depth': 1}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:31,765] Trial 30 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 155, 'learning_rate': 0.03368407285203739, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:32,410] Trial 31 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 158, 'learning_rate': 0.03609577977948278, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:33,003] Trial 32 finished with value: 0.78529393312002 and parameters: {'n_estimators': 165, 'learning_rate': 0.04694514475778045, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:33,554] Trial 33 finished with value: 0.7852970700796786 and parameters: {'n_estimators': 153, 'learning_rate': 0.03138661827876278, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:33,963] Trial 34 finished with value: 0.7789478637304723 and parameters: {'n_estimators': 179, 'learning_rate': 0.06232780732218228, 'max_depth': 1}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:34,551] Trial 35 finished with value: 0.7860907208733294 and parameters: {'n_estimators': 159, 'learning_rate': 0.04014515033092264, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:34,880] Trial 36 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 128, 'learning_rate': 0.058395607380671496, 'max_depth': 1}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:35,605] Trial 37 finished with value: 0.7860907208733294 and parameters: {'n_estimators': 194, 'learning_rate': 0.02263182040636264, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:37,219] Trial 38 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 165, 'learning_rate': 0.01255407466643157, 'max_depth': 5}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:37,814] Trial 39 finished with value: 0.7789635485287659 and parameters: {'n_estimators': 150, 'learning_rate': 0.14421564143403162, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:38,531] Trial 40 finished with value: 0.784490871447393 and parameters: {'n_estimators': 134, 'learning_rate': 0.030754945670217557, 'max_depth': 3}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:39,084] Trial 41 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 147, 'learning_rate': 0.018164297065899473, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:39,593] Trial 42 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 135, 'learning_rate': 0.013302108944157879, 'max_depth': 2}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:39,997] Trial 43 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 172, 'learning_rate': 0.0270238336600823, 'max_depth': 1}. Best is trial 13 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:17:40,456] Trial 44 finished with value: 0.7884685362946233 and parameters: {'n_estimators': 121, 'learning_rate': 0.04679999354567613, 'max_depth': 2}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:41,079] Trial 45 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 118, 'learning_rate': 0.04774285847398012, 'max_depth': 3}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:41,432] Trial 46 finished with value: 0.7852876592007026 and parameters: {'n_estimators': 95, 'learning_rate': 0.07338790495258375, 'max_depth': 2}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:42,389] Trial 47 finished with value: 0.7829098437794089 and parameters: {'n_estimators': 186, 'learning_rate': 0.02080340075236626, 'max_depth': 3}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:42,638] Trial 48 finished with value: 0.7837129054520359 and parameters: {'n_estimators': 107, 'learning_rate': 0.041366670658025774, 'max_depth': 1}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:44,124] Trial 49 finished with value: 0.7456835435096305 and parameters: {'n_estimators': 160, 'learning_rate': 0.12365764152286204, 'max_depth': 5}. Best is trial 44 with value: 0.7884685362946233.\n",
      "[I 2024-12-02 18:17:44,125] A new study created in memory with name: no-name-f81ec0a1-0f8f-4d67-ae54-ffb4b94e22b7\n",
      "[I 2024-12-02 18:17:44,926] Trial 0 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 101, 'learning_rate': 0.01177826335866943, 'max_depth': 4}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:45,925] Trial 1 finished with value: 0.7718301022648848 and parameters: {'n_estimators': 110, 'learning_rate': 0.07771344301968783, 'max_depth': 5}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:46,910] Trial 2 finished with value: 0.7742204655248133 and parameters: {'n_estimators': 143, 'learning_rate': 0.07264331152595922, 'max_depth': 4}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:47,301] Trial 3 finished with value: 0.7781542129368215 and parameters: {'n_estimators': 170, 'learning_rate': 0.08000488732701921, 'max_depth': 1}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:48,628] Trial 4 finished with value: 0.7512359621055273 and parameters: {'n_estimators': 189, 'learning_rate': 0.11160683715616822, 'max_depth': 4}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:49,018] Trial 5 finished with value: 0.7797352406048057 and parameters: {'n_estimators': 172, 'learning_rate': 0.08413955215471716, 'max_depth': 1}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:49,876] Trial 6 finished with value: 0.7536169144864797 and parameters: {'n_estimators': 125, 'learning_rate': 0.16845091275464993, 'max_depth': 4}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:50,411] Trial 7 finished with value: 0.7741985068072024 and parameters: {'n_estimators': 135, 'learning_rate': 0.17930664018587225, 'max_depth': 2}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:51,252] Trial 8 finished with value: 0.7773762469414643 and parameters: {'n_estimators': 168, 'learning_rate': 0.0608488579487137, 'max_depth': 3}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:51,714] Trial 9 finished with value: 0.7559821820691386 and parameters: {'n_estimators': 131, 'learning_rate': 0.624790957216283, 'max_depth': 2}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:52,304] Trial 10 finished with value: 0.7765794591881547 and parameters: {'n_estimators': 64, 'learning_rate': 0.01166090734745792, 'max_depth': 5}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:52,500] Trial 11 finished with value: 0.7535855448898927 and parameters: {'n_estimators': 85, 'learning_rate': 0.010180834414134326, 'max_depth': 1}. Best is trial 0 with value: 0.7845002823263693.\n",
      "[I 2024-12-02 18:17:53,159] Trial 12 finished with value: 0.788459125415647 and parameters: {'n_estimators': 92, 'learning_rate': 0.02530002485725616, 'max_depth': 3}. Best is trial 12 with value: 0.788459125415647.\n",
      "[I 2024-12-02 18:17:53,819] Trial 13 finished with value: 0.7868686868686868 and parameters: {'n_estimators': 92, 'learning_rate': 0.02676537362693083, 'max_depth': 3}. Best is trial 12 with value: 0.788459125415647.\n",
      "[I 2024-12-02 18:17:54,261] Trial 14 finished with value: 0.7892559131689566 and parameters: {'n_estimators': 59, 'learning_rate': 0.032642171237110586, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:54,522] Trial 15 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 50, 'learning_rate': 0.030328283876507354, 'max_depth': 2}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:54,923] Trial 16 finished with value: 0.7876623376623376 and parameters: {'n_estimators': 74, 'learning_rate': 0.03632505740215531, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:55,127] Trial 17 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 53, 'learning_rate': 0.02098583277817359, 'max_depth': 2}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:55,565] Trial 18 finished with value: 0.784490871447393 and parameters: {'n_estimators': 76, 'learning_rate': 0.043867909561402685, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:56,092] Trial 19 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 102, 'learning_rate': 0.021723344164725173, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:56,874] Trial 20 finished with value: 0.7884653993349644 and parameters: {'n_estimators': 111, 'learning_rate': 0.01747357759382852, 'max_depth': 4}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:57,774] Trial 21 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 112, 'learning_rate': 0.01746985500891212, 'max_depth': 4}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:58,541] Trial 22 finished with value: 0.7876623376623376 and parameters: {'n_estimators': 148, 'learning_rate': 0.017229315317807053, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:17:59,632] Trial 23 finished with value: 0.7789572746094485 and parameters: {'n_estimators': 117, 'learning_rate': 0.044834036655932205, 'max_depth': 5}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:00,120] Trial 24 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 66, 'learning_rate': 0.014505273297733458, 'max_depth': 4}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:00,647] Trial 25 finished with value: 0.7401530836313445 and parameters: {'n_estimators': 101, 'learning_rate': 0.7796656185373539, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:00,984] Trial 26 finished with value: 0.7845065562456867 and parameters: {'n_estimators': 81, 'learning_rate': 0.050068825414916474, 'max_depth': 2}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:01,678] Trial 27 finished with value: 0.736940836940837 and parameters: {'n_estimators': 101, 'learning_rate': 0.39623976419346757, 'max_depth': 4}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:02,448] Trial 28 finished with value: 0.7821161929857581 and parameters: {'n_estimators': 152, 'learning_rate': 0.03292484996924806, 'max_depth': 3}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:03,026] Trial 29 finished with value: 0.7765763222284962 and parameters: {'n_estimators': 62, 'learning_rate': 0.013872157457603205, 'max_depth': 5}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:03,870] Trial 30 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 122, 'learning_rate': 0.023609066733176337, 'max_depth': 4}. Best is trial 14 with value: 0.7892559131689566.\n",
      "[I 2024-12-02 18:18:04,366] Trial 31 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 94, 'learning_rate': 0.0192307123153433, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:04,900] Trial 32 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 104, 'learning_rate': 0.01812459810598321, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:05,377] Trial 33 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 92, 'learning_rate': 0.020710977867200935, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:05,702] Trial 34 finished with value: 0.7829067068197503 and parameters: {'n_estimators': 87, 'learning_rate': 0.013417642427998536, 'max_depth': 2}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:06,213] Trial 35 finished with value: 0.7821193299454169 and parameters: {'n_estimators': 99, 'learning_rate': 0.03549707560818855, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:06,591] Trial 36 finished with value: 0.79004329004329 and parameters: {'n_estimators': 70, 'learning_rate': 0.01976818561820054, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:06,889] Trial 37 finished with value: 0.78529393312002 and parameters: {'n_estimators': 78, 'learning_rate': 0.0580393410984028, 'max_depth': 2}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:07,275] Trial 38 finished with value: 0.7749858836815358 and parameters: {'n_estimators': 73, 'learning_rate': 0.09855952423157395, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:07,616] Trial 39 finished with value: 0.7789510006901311 and parameters: {'n_estimators': 92, 'learning_rate': 0.010144565330477815, 'max_depth': 2}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:08,150] Trial 40 finished with value: 0.7591567852437417 and parameters: {'n_estimators': 105, 'learning_rate': 0.2550478016654591, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:08,457] Trial 41 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 58, 'learning_rate': 0.019186183603747266, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:08,818] Trial 42 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 69, 'learning_rate': 0.02846649940531428, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:09,302] Trial 43 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 69, 'learning_rate': 0.015800748034084367, 'max_depth': 4}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:09,751] Trial 44 finished with value: 0.79004329004329 and parameters: {'n_estimators': 87, 'learning_rate': 0.02379792787866345, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:10,241] Trial 45 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 95, 'learning_rate': 0.012195955045719133, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:10,809] Trial 46 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 82, 'learning_rate': 0.027993023342068657, 'max_depth': 4}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:11,075] Trial 47 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 71, 'learning_rate': 0.03992419112877955, 'max_depth': 2}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:11,280] Trial 48 finished with value: 0.7789447267708137 and parameters: {'n_estimators': 87, 'learning_rate': 0.14713540255412016, 'max_depth': 1}. Best is trial 31 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:12,237] Trial 49 finished with value: 0.7805383022774327 and parameters: {'n_estimators': 192, 'learning_rate': 0.06941770719098576, 'max_depth': 3}. Best is trial 31 with value: 0.7924211054645836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "Added 138 new labeled samples.\n",
      "--- Iteration 2 ---\n",
      "Added 125 new labeled samples.\n",
      "--- Iteration 3 ---\n",
      "Added 131 new labeled samples.\n",
      "--- Iteration 4 ---\n",
      "Added 45 new labeled samples.\n",
      "--- Iteration 5 ---\n",
      "Added 77 new labeled samples.\n",
      "--- Iteration 6 ---\n",
      "Added 61 new labeled samples.\n",
      "--- Iteration 7 ---\n",
      "Added 10 new labeled samples.\n",
      "--- Iteration 8 ---\n",
      "Added 21 new labeled samples.\n",
      "--- Iteration 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:18:13,362] A new study created in memory with name: no-name-793e3fc5-0fb4-4ef3-9b7e-7b6ece0cb3bc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12 new labeled samples.\n",
      "--- Iteration 10 ---\n",
      "Added 17 new labeled samples.\n",
      "Accuracy on test set of co-training with Gradient Boosting with a split ratio of 20%/80%: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:18:14,942] Trial 0 finished with value: 0.7472645711776147 and parameters: {'n_estimators': 166, 'learning_rate': 0.5138565887268725, 'max_depth': 5}. Best is trial 0 with value: 0.7472645711776147.\n",
      "[I 2024-12-02 18:18:15,281] Trial 1 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 147, 'learning_rate': 0.03144639054389224, 'max_depth': 1}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:15,892] Trial 2 finished with value: 0.7464834682225987 and parameters: {'n_estimators': 64, 'learning_rate': 0.38913836895305604, 'max_depth': 5}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:17,399] Trial 3 finished with value: 0.7765637743898613 and parameters: {'n_estimators': 165, 'learning_rate': 0.018635542886065014, 'max_depth': 5}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:17,909] Trial 4 finished with value: 0.7441119267206224 and parameters: {'n_estimators': 74, 'learning_rate': 0.6245619433067048, 'max_depth': 4}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:18,415] Trial 5 finished with value: 0.7607378129117259 and parameters: {'n_estimators': 56, 'learning_rate': 0.16186951963111576, 'max_depth': 5}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:18,779] Trial 6 finished with value: 0.7725923834619486 and parameters: {'n_estimators': 163, 'learning_rate': 0.3086621968951634, 'max_depth': 1}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:20,027] Trial 7 finished with value: 0.7639249639249639 and parameters: {'n_estimators': 182, 'learning_rate': 0.08249931592299073, 'max_depth': 4}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:20,903] Trial 8 finished with value: 0.7678461634983373 and parameters: {'n_estimators': 174, 'learning_rate': 0.3738560434133144, 'max_depth': 2}. Best is trial 1 with value: 0.7829161176987263.\n",
      "[I 2024-12-02 18:18:21,998] Trial 9 finished with value: 0.7876623376623376 and parameters: {'n_estimators': 186, 'learning_rate': 0.014242703855027624, 'max_depth': 3}. Best is trial 9 with value: 0.7876623376623376.\n",
      "[I 2024-12-02 18:18:22,573] Trial 10 finished with value: 0.786084446954012 and parameters: {'n_estimators': 109, 'learning_rate': 0.01097806024683304, 'max_depth': 3}. Best is trial 9 with value: 0.7876623376623376.\n",
      "[I 2024-12-02 18:18:23,111] Trial 11 finished with value: 0.7876654746219962 and parameters: {'n_estimators': 105, 'learning_rate': 0.011584790275594422, 'max_depth': 3}. Best is trial 11 with value: 0.7876654746219962.\n",
      "[I 2024-12-02 18:18:23,749] Trial 12 finished with value: 0.7797383775644645 and parameters: {'n_estimators': 101, 'learning_rate': 0.04506359672383861, 'max_depth': 3}. Best is trial 11 with value: 0.7876654746219962.\n",
      "[I 2024-12-02 18:18:24,827] Trial 13 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 200, 'learning_rate': 0.010152853898861494, 'max_depth': 2}. Best is trial 11 with value: 0.7876654746219962.\n",
      "[I 2024-12-02 18:18:25,512] Trial 14 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 133, 'learning_rate': 0.025463809600678535, 'max_depth': 2}. Best is trial 11 with value: 0.7876654746219962.\n",
      "[I 2024-12-02 18:18:26,140] Trial 15 finished with value: 0.7749952945605119 and parameters: {'n_estimators': 86, 'learning_rate': 0.06749532205407285, 'max_depth': 4}. Best is trial 11 with value: 0.7876654746219962.\n",
      "[I 2024-12-02 18:18:26,838] Trial 16 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 123, 'learning_rate': 0.01684793023499161, 'max_depth': 3}. Best is trial 16 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:18:27,284] Trial 17 finished with value: 0.7884653993349645 and parameters: {'n_estimators': 119, 'learning_rate': 0.04130209954380536, 'max_depth': 2}. Best is trial 16 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:18:27,747] Trial 18 finished with value: 0.7741953698475437 and parameters: {'n_estimators': 126, 'learning_rate': 0.12811429648084519, 'max_depth': 2}. Best is trial 16 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:18:28,217] Trial 19 finished with value: 0.7821193299454169 and parameters: {'n_estimators': 143, 'learning_rate': 0.05149474159338952, 'max_depth': 1}. Best is trial 16 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:18:28,696] Trial 20 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 114, 'learning_rate': 0.02720720797550023, 'max_depth': 2}. Best is trial 16 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:18:29,197] Trial 21 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 92, 'learning_rate': 0.01825534038759572, 'max_depth': 3}. Best is trial 21 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:18:29,742] Trial 22 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 90, 'learning_rate': 0.018573477004393806, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:30,229] Trial 23 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 90, 'learning_rate': 0.01806121193352293, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:30,858] Trial 24 finished with value: 0.7892590501286152 and parameters: {'n_estimators': 89, 'learning_rate': 0.019914846762695403, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:31,282] Trial 25 finished with value: 0.7837003576134011 and parameters: {'n_estimators': 82, 'learning_rate': 0.03434489629852777, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:31,945] Trial 26 finished with value: 0.7544011544011544 and parameters: {'n_estimators': 96, 'learning_rate': 0.22013212891538395, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:32,337] Trial 27 finished with value: 0.7369753434970826 and parameters: {'n_estimators': 71, 'learning_rate': 0.9604198447735492, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:32,844] Trial 28 finished with value: 0.79004329004329 and parameters: {'n_estimators': 93, 'learning_rate': 0.024083513711092384, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:33,224] Trial 29 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 52, 'learning_rate': 0.06364010965245923, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:33,626] Trial 30 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 76, 'learning_rate': 0.014542713028888736, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:34,285] Trial 31 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 128, 'learning_rate': 0.016526542298472623, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:34,980] Trial 32 finished with value: 0.7844877344877345 and parameters: {'n_estimators': 136, 'learning_rate': 0.02287345309378589, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:35,314] Trial 33 finished with value: 0.7900464270029486 and parameters: {'n_estimators': 63, 'learning_rate': 0.03293555561911687, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:35,702] Trial 34 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 101, 'learning_rate': 0.01564867089660897, 'max_depth': 2}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:36,786] Trial 35 finished with value: 0.7837160424116946 and parameters: {'n_estimators': 153, 'learning_rate': 0.017773522056271335, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:37,384] Trial 36 finished with value: 0.7821161929857581 and parameters: {'n_estimators': 112, 'learning_rate': 0.03489037907963354, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:37,964] Trial 37 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 80, 'learning_rate': 0.012888296374137548, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:38,533] Trial 38 finished with value: 0.7797415145241231 and parameters: {'n_estimators': 60, 'learning_rate': 0.020249585524484866, 'max_depth': 5}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:38,787] Trial 39 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 67, 'learning_rate': 0.11007725665946717, 'max_depth': 2}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:39,438] Trial 40 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 94, 'learning_rate': 0.028189555344067283, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:40,079] Trial 41 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 126, 'learning_rate': 0.016146198831442842, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:40,685] Trial 42 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 117, 'learning_rate': 0.019384284261132104, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:41,370] Trial 43 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 134, 'learning_rate': 0.013669204751967805, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:42,130] Trial 44 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 149, 'learning_rate': 0.012637278394224566, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:42,913] Trial 45 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 150, 'learning_rate': 0.010426258306613284, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:43,721] Trial 46 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 155, 'learning_rate': 0.010448961617573532, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:44,268] Trial 47 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 143, 'learning_rate': 0.012604439829324837, 'max_depth': 2}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:45,271] Trial 48 finished with value: 0.790833803877282 and parameters: {'n_estimators': 170, 'learning_rate': 0.012722784387177465, 'max_depth': 3}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:46,388] Trial 49 finished with value: 0.7876717485413136 and parameters: {'n_estimators': 160, 'learning_rate': 0.01010067339842439, 'max_depth': 4}. Best is trial 22 with value: 0.7924211054645836.\n",
      "[I 2024-12-02 18:18:46,389] A new study created in memory with name: no-name-5bd2f175-039f-4ee3-ab06-a71d81bc80b5\n",
      "[I 2024-12-02 18:18:46,911] Trial 0 finished with value: 0.7757732605558691 and parameters: {'n_estimators': 56, 'learning_rate': 0.041649490128101194, 'max_depth': 5}. Best is trial 0 with value: 0.7757732605558691.\n",
      "[I 2024-12-02 18:18:47,650] Trial 1 finished with value: 0.7433120020076542 and parameters: {'n_estimators': 100, 'learning_rate': 0.30200263472137523, 'max_depth': 4}. Best is trial 0 with value: 0.7757732605558691.\n",
      "[I 2024-12-02 18:18:47,843] Trial 2 finished with value: 0.7765512265512264 and parameters: {'n_estimators': 85, 'learning_rate': 0.3696175807837996, 'max_depth': 1}. Best is trial 2 with value: 0.7765512265512264.\n",
      "[I 2024-12-02 18:18:49,231] Trial 3 finished with value: 0.7813445009097183 and parameters: {'n_estimators': 127, 'learning_rate': 0.06660177809415743, 'max_depth': 4}. Best is trial 3 with value: 0.7813445009097183.\n",
      "[I 2024-12-02 18:18:50,550] Trial 4 finished with value: 0.7813476378693769 and parameters: {'n_estimators': 155, 'learning_rate': 0.04470739713930029, 'max_depth': 4}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:50,977] Trial 5 finished with value: 0.7749921576008532 and parameters: {'n_estimators': 106, 'learning_rate': 0.14405276238623266, 'max_depth': 2}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:51,854] Trial 6 finished with value: 0.7520358868184955 and parameters: {'n_estimators': 111, 'learning_rate': 0.1705827887514842, 'max_depth': 4}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:52,859] Trial 7 finished with value: 0.7393437480394003 and parameters: {'n_estimators': 142, 'learning_rate': 0.3556505642745387, 'max_depth': 4}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:53,594] Trial 8 finished with value: 0.7741985068072024 and parameters: {'n_estimators': 137, 'learning_rate': 0.08435824282836653, 'max_depth': 3}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:55,515] Trial 9 finished with value: 0.7488299140473054 and parameters: {'n_estimators': 200, 'learning_rate': 0.2780113246593906, 'max_depth': 5}. Best is trial 4 with value: 0.7813476378693769.\n",
      "[I 2024-12-02 18:18:56,275] Trial 10 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 178, 'learning_rate': 0.01218017723084788, 'max_depth': 2}. Best is trial 10 with value: 0.7860813099943534.\n",
      "[I 2024-12-02 18:18:56,975] Trial 11 finished with value: 0.7884622623753058 and parameters: {'n_estimators': 176, 'learning_rate': 0.01144548104309375, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:18:57,653] Trial 12 finished with value: 0.787668611581655 and parameters: {'n_estimators': 182, 'learning_rate': 0.01010237860289742, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:18:58,043] Trial 13 finished with value: 0.7734017190538929 and parameters: {'n_estimators': 173, 'learning_rate': 0.01044136782982034, 'max_depth': 1}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:18:58,736] Trial 14 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 197, 'learning_rate': 0.02059715810413897, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:18:59,586] Trial 15 finished with value: 0.7298293493945668 and parameters: {'n_estimators': 168, 'learning_rate': 0.8379021223367803, 'max_depth': 3}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:00,250] Trial 16 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 183, 'learning_rate': 0.021485643698547954, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:00,603] Trial 17 finished with value: 0.7789447267708136 and parameters: {'n_estimators': 154, 'learning_rate': 0.019141184019627926, 'max_depth': 1}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:01,397] Trial 18 finished with value: 0.7805383022774327 and parameters: {'n_estimators': 155, 'learning_rate': 0.0349300358493369, 'max_depth': 3}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:02,083] Trial 19 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 185, 'learning_rate': 0.015229344252783234, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:02,454] Trial 20 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 163, 'learning_rate': 0.028865486434463024, 'max_depth': 1}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:03,169] Trial 21 finished with value: 0.7853002070393375 and parameters: {'n_estimators': 199, 'learning_rate': 0.019177851008533052, 'max_depth': 2}. Best is trial 11 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:19:04,197] Trial 22 finished with value: 0.79004329004329 and parameters: {'n_estimators': 188, 'learning_rate': 0.010426204493277056, 'max_depth': 3}. Best is trial 22 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:19:05,214] Trial 23 finished with value: 0.7900464270029486 and parameters: {'n_estimators': 184, 'learning_rate': 0.010804775333281535, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:06,176] Trial 24 finished with value: 0.7876592007026788 and parameters: {'n_estimators': 189, 'learning_rate': 0.013887283916055345, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:07,002] Trial 25 finished with value: 0.7805351653177739 and parameters: {'n_estimators': 166, 'learning_rate': 0.027883031864105217, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:07,701] Trial 26 finished with value: 0.7749858836815358 and parameters: {'n_estimators': 141, 'learning_rate': 0.06106635223168793, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:08,721] Trial 27 finished with value: 0.7860718991153772 and parameters: {'n_estimators': 187, 'learning_rate': 0.015382110703606797, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:09,041] Trial 28 finished with value: 0.7718301022648848 and parameters: {'n_estimators': 60, 'learning_rate': 0.010034009631732892, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:09,508] Trial 29 finished with value: 0.7789541376497897 and parameters: {'n_estimators': 50, 'learning_rate': 0.04029117449113093, 'max_depth': 5}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:10,132] Trial 30 finished with value: 0.7868843716669803 and parameters: {'n_estimators': 175, 'learning_rate': 0.024410086028344002, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:10,882] Trial 31 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 190, 'learning_rate': 0.013689199060175426, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:11,534] Trial 32 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 176, 'learning_rate': 0.01019231292170227, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:11,911] Trial 33 finished with value: 0.7781510759771628 and parameters: {'n_estimators': 162, 'learning_rate': 0.016024763789061463, 'max_depth': 1}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:12,424] Trial 34 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 81, 'learning_rate': 0.011775430191453967, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:13,801] Trial 35 finished with value: 0.7765920070267895 and parameters: {'n_estimators': 191, 'learning_rate': 0.05248857380964121, 'max_depth': 4}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:14,262] Trial 36 finished with value: 0.7884685362946232 and parameters: {'n_estimators': 127, 'learning_rate': 0.03398683961709863, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:14,913] Trial 37 finished with value: 0.7797383775644645 and parameters: {'n_estimators': 125, 'learning_rate': 0.03387015398954834, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:15,513] Trial 38 finished with value: 0.7686586360499404 and parameters: {'n_estimators': 87, 'learning_rate': 0.09477452268825615, 'max_depth': 4}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:15,813] Trial 39 finished with value: 0.7741985068072024 and parameters: {'n_estimators': 130, 'learning_rate': 0.01809116895714074, 'max_depth': 1}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:16,704] Trial 40 finished with value: 0.7599567099567099 and parameters: {'n_estimators': 117, 'learning_rate': 0.13558517263070652, 'max_depth': 4}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:17,263] Trial 41 finished with value: 0.787668611581655 and parameters: {'n_estimators': 149, 'learning_rate': 0.013185699437515307, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:17,922] Trial 42 finished with value: 0.7876780224606311 and parameters: {'n_estimators': 181, 'learning_rate': 0.024356561096651005, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:18,267] Trial 43 finished with value: 0.7852876592007026 and parameters: {'n_estimators': 92, 'learning_rate': 0.025781724906726068, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:18,861] Trial 44 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 169, 'learning_rate': 0.05128982521809535, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:19,245] Trial 45 finished with value: 0.7813319530710835 and parameters: {'n_estimators': 74, 'learning_rate': 0.07059344779423594, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:19,937] Trial 46 finished with value: 0.7829192546583851 and parameters: {'n_estimators': 194, 'learning_rate': 0.017037173995640077, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:20,836] Trial 47 finished with value: 0.7829067068197503 and parameters: {'n_estimators': 179, 'learning_rate': 0.02280705246978968, 'max_depth': 3}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:21,170] Trial 48 finished with value: 0.7734017190538929 and parameters: {'n_estimators': 145, 'learning_rate': 0.012154194293537483, 'max_depth': 1}. Best is trial 23 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:19:21,754] Trial 49 finished with value: 0.7876748855009724 and parameters: {'n_estimators': 161, 'learning_rate': 0.032596770778182065, 'max_depth': 2}. Best is trial 23 with value: 0.7900464270029486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "Added 27 new labeled samples.\n",
      "--- Iteration 2 ---\n",
      "Added 23 new labeled samples.\n",
      "--- Iteration 3 ---\n",
      "Added 30 new labeled samples.\n",
      "--- Iteration 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:19:22,525] A new study created in memory with name: no-name-218771df-570f-45cb-9fad-48241410ca0f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 19 new labeled samples.\n",
      "--- Iteration 5 ---\n",
      "No more confident predictions; stopping training.\n",
      "Accuracy on test set of co-training with Gradient Boosting with a split ratio of 30%/70%: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:19:23,130] Trial 0 finished with value: 0.7472520233389799 and parameters: {'n_estimators': 170, 'learning_rate': 0.8316860169769607, 'max_depth': 2}. Best is trial 0 with value: 0.7472520233389799.\n",
      "[I 2024-12-02 18:19:23,577] Trial 1 finished with value: 0.7789604115691071 and parameters: {'n_estimators': 65, 'learning_rate': 0.012007685554069438, 'max_depth': 4}. Best is trial 1 with value: 0.7789604115691071.\n",
      "[I 2024-12-02 18:19:24,130] Trial 2 finished with value: 0.7868749607880042 and parameters: {'n_estimators': 154, 'learning_rate': 0.011672173948385347, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:24,501] Trial 3 finished with value: 0.7559821820691386 and parameters: {'n_estimators': 74, 'learning_rate': 0.32262186016471195, 'max_depth': 3}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:25,339] Trial 4 finished with value: 0.7773762469414643 and parameters: {'n_estimators': 124, 'learning_rate': 0.07793961659910904, 'max_depth': 4}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:25,785] Trial 5 finished with value: 0.7512453729845033 and parameters: {'n_estimators': 88, 'learning_rate': 0.39803406677011677, 'max_depth': 3}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:26,526] Trial 6 finished with value: 0.7733891712152582 and parameters: {'n_estimators': 76, 'learning_rate': 0.030913916279849473, 'max_depth': 5}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:27,167] Trial 7 finished with value: 0.751239099065186 and parameters: {'n_estimators': 94, 'learning_rate': 0.27134890985332405, 'max_depth': 4}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:27,492] Trial 8 finished with value: 0.7710395884308927 and parameters: {'n_estimators': 91, 'learning_rate': 0.49216882964427006, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:27,835] Trial 9 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 95, 'learning_rate': 0.015387686154901244, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:28,282] Trial 10 finished with value: 0.7805288913984565 and parameters: {'n_estimators': 197, 'learning_rate': 0.07606957412816402, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:28,605] Trial 11 finished with value: 0.7710270405922579 and parameters: {'n_estimators': 139, 'learning_rate': 0.010071087935032755, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:29,061] Trial 12 finished with value: 0.7813319530710835 and parameters: {'n_estimators': 124, 'learning_rate': 0.0257756540489793, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:29,663] Trial 13 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 165, 'learning_rate': 0.025011751388852164, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:30,027] Trial 14 finished with value: 0.7837129054520359 and parameters: {'n_estimators': 156, 'learning_rate': 0.03681749966444652, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:30,972] Trial 15 finished with value: 0.7559915929481147 and parameters: {'n_estimators': 187, 'learning_rate': 0.15773213520150847, 'max_depth': 3}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:31,602] Trial 16 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 163, 'learning_rate': 0.019891046256977258, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:31,928] Trial 17 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 139, 'learning_rate': 0.04625431350476102, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:32,581] Trial 18 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 182, 'learning_rate': 0.0505310246920619, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:33,297] Trial 19 finished with value: 0.7836972206537423 and parameters: {'n_estimators': 142, 'learning_rate': 0.020086189269593924, 'max_depth': 3}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:33,548] Trial 20 finished with value: 0.7773574251835121 and parameters: {'n_estimators': 110, 'learning_rate': 0.1442078707124646, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:33,869] Trial 21 finished with value: 0.7837097684923771 and parameters: {'n_estimators': 142, 'learning_rate': 0.04639231139818794, 'max_depth': 1}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:34,468] Trial 22 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 153, 'learning_rate': 0.01493988392439957, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:35,019] Trial 23 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 154, 'learning_rate': 0.014999986992954746, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:35,700] Trial 24 finished with value: 0.7860907208733295 and parameters: {'n_estimators': 173, 'learning_rate': 0.022529224094634828, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:36,676] Trial 25 finished with value: 0.7837003576134011 and parameters: {'n_estimators': 178, 'learning_rate': 0.02209756465653555, 'max_depth': 3}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:37,400] Trial 26 finished with value: 0.78529393312002 and parameters: {'n_estimators': 200, 'learning_rate': 0.03256336732279799, 'max_depth': 2}. Best is trial 2 with value: 0.7868749607880042.\n",
      "[I 2024-12-02 18:19:38,290] Trial 27 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 171, 'learning_rate': 0.01008811467342308, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:39,436] Trial 28 finished with value: 0.7876717485413136 and parameters: {'n_estimators': 165, 'learning_rate': 0.01015179045209577, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:41,169] Trial 29 finished with value: 0.7821193299454169 and parameters: {'n_estimators': 186, 'learning_rate': 0.010594786327274279, 'max_depth': 5}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:42,367] Trial 30 finished with value: 0.7298199385155907 and parameters: {'n_estimators': 168, 'learning_rate': 0.7186502826719524, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:43,511] Trial 31 finished with value: 0.7892590501286152 and parameters: {'n_estimators': 164, 'learning_rate': 0.013998580749320073, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:44,576] Trial 32 finished with value: 0.7908400777965994 and parameters: {'n_estimators': 151, 'learning_rate': 0.013403769442255534, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:45,655] Trial 33 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 132, 'learning_rate': 0.014570828212001974, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:46,685] Trial 34 finished with value: 0.7900495639626074 and parameters: {'n_estimators': 132, 'learning_rate': 0.015208315629069564, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:47,893] Trial 35 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 114, 'learning_rate': 0.017319426480561183, 'max_depth': 5}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:48,788] Trial 36 finished with value: 0.7876748855009724 and parameters: {'n_estimators': 112, 'learning_rate': 0.013534605928423279, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:50,242] Trial 37 finished with value: 0.7789510006901311 and parameters: {'n_estimators': 150, 'learning_rate': 0.013088327190634729, 'max_depth': 5}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:50,905] Trial 38 finished with value: 0.7773605621431707 and parameters: {'n_estimators': 132, 'learning_rate': 0.06736402468809678, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:52,088] Trial 39 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 174, 'learning_rate': 0.01845942871833323, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:53,155] Trial 40 finished with value: 0.7575851684547337 and parameters: {'n_estimators': 159, 'learning_rate': 0.10643536188262306, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:54,042] Trial 41 finished with value: 0.7900495639626074 and parameters: {'n_estimators': 128, 'learning_rate': 0.013178739091542737, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:55,066] Trial 42 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 148, 'learning_rate': 0.012124023748357578, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:55,736] Trial 43 finished with value: 0.784490871447393 and parameters: {'n_estimators': 132, 'learning_rate': 0.028096353391288922, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:56,146] Trial 44 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 58, 'learning_rate': 0.0174796813217349, 'max_depth': 4}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:57,512] Trial 45 finished with value: 0.7797383775644645 and parameters: {'n_estimators': 146, 'learning_rate': 0.011644210982621252, 'max_depth': 5}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:58,136] Trial 46 finished with value: 0.7829098437794089 and parameters: {'n_estimators': 119, 'learning_rate': 0.03781088042121225, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:58,668] Trial 47 finished with value: 0.7900401530836312 and parameters: {'n_estimators': 103, 'learning_rate': 0.01278069548445235, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:59,203] Trial 48 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 103, 'learning_rate': 0.010122917791166133, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:59,712] Trial 49 finished with value: 0.7678649852562895 and parameters: {'n_estimators': 101, 'learning_rate': 0.2654081794753995, 'max_depth': 3}. Best is trial 27 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:19:59,713] A new study created in memory with name: no-name-fd7980a9-59c7-4ff8-8e5b-31eb0dc631a7\n",
      "[I 2024-12-02 18:20:00,105] Trial 0 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 111, 'learning_rate': 0.07275717425971232, 'max_depth': 2}. Best is trial 0 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:20:01,562] Trial 1 finished with value: 0.7773605621431707 and parameters: {'n_estimators': 162, 'learning_rate': 0.014240556945122669, 'max_depth': 5}. Best is trial 0 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:20:02,456] Trial 2 finished with value: 0.7448993035949558 and parameters: {'n_estimators': 181, 'learning_rate': 0.8930269433076421, 'max_depth': 3}. Best is trial 0 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:20:02,768] Trial 3 finished with value: 0.7552167639124161 and parameters: {'n_estimators': 88, 'learning_rate': 0.6574637763872077, 'max_depth': 2}. Best is trial 0 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:20:03,151] Trial 4 finished with value: 0.7765763222284962 and parameters: {'n_estimators': 109, 'learning_rate': 0.2042222721618613, 'max_depth': 2}. Best is trial 0 with value: 0.7837066315327185.\n",
      "[I 2024-12-02 18:20:03,339] Trial 5 finished with value: 0.7837129054520359 and parameters: {'n_estimators': 83, 'learning_rate': 0.07028674493969533, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:03,865] Trial 6 finished with value: 0.7472551602986386 and parameters: {'n_estimators': 59, 'learning_rate': 0.5751984692219808, 'max_depth': 5}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:04,290] Trial 7 finished with value: 0.7821224669050755 and parameters: {'n_estimators': 193, 'learning_rate': 0.025644700276292277, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:05,156] Trial 8 finished with value: 0.7797477884434405 and parameters: {'n_estimators': 177, 'learning_rate': 0.058444073588969525, 'max_depth': 3}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:05,809] Trial 9 finished with value: 0.7789415898111549 and parameters: {'n_estimators': 131, 'learning_rate': 0.034134285416648105, 'max_depth': 3}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:05,932] Trial 10 finished with value: 0.7805383022774327 and parameters: {'n_estimators': 51, 'learning_rate': 0.17485346825925047, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:06,251] Trial 11 finished with value: 0.7797415145241231 and parameters: {'n_estimators': 89, 'learning_rate': 0.1267378389430177, 'max_depth': 2}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:06,528] Trial 12 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 123, 'learning_rate': 0.06479889816460602, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:06,816] Trial 13 finished with value: 0.7702365267582658 and parameters: {'n_estimators': 80, 'learning_rate': 0.30186444515418576, 'max_depth': 2}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:07,805] Trial 14 finished with value: 0.7781855825334085 and parameters: {'n_estimators': 148, 'learning_rate': 0.07078164171428221, 'max_depth': 4}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:08,053] Trial 15 finished with value: 0.7805351653177739 and parameters: {'n_estimators': 109, 'learning_rate': 0.032179591534690855, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:08,331] Trial 16 finished with value: 0.7789510006901311 and parameters: {'n_estimators': 76, 'learning_rate': 0.010089304063707751, 'max_depth': 2}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:09,034] Trial 17 finished with value: 0.7670932931802497 and parameters: {'n_estimators': 105, 'learning_rate': 0.11705664705595413, 'max_depth': 4}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:09,339] Trial 18 finished with value: 0.7717987326682978 and parameters: {'n_estimators': 133, 'learning_rate': 0.35063929380351916, 'max_depth': 1}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:09,601] Trial 19 finished with value: 0.7829255285777025 and parameters: {'n_estimators': 71, 'learning_rate': 0.05128717637189117, 'max_depth': 2}. Best is trial 5 with value: 0.7837129054520359.\n",
      "[I 2024-12-02 18:20:10,593] Trial 20 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 147, 'learning_rate': 0.02032455631757185, 'max_depth': 4}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:11,638] Trial 21 finished with value: 0.7845002823263693 and parameters: {'n_estimators': 152, 'learning_rate': 0.020544444690492877, 'max_depth': 4}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:12,651] Trial 22 finished with value: 0.78529393312002 and parameters: {'n_estimators': 150, 'learning_rate': 0.017106768544182128, 'max_depth': 4}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:13,692] Trial 23 finished with value: 0.7845034192860278 and parameters: {'n_estimators': 152, 'learning_rate': 0.020053121721454528, 'max_depth': 4}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:14,983] Trial 24 finished with value: 0.786084446954012 and parameters: {'n_estimators': 147, 'learning_rate': 0.017497901204667373, 'max_depth': 4}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:17,054] Trial 25 finished with value: 0.7813225421921073 and parameters: {'n_estimators': 169, 'learning_rate': 0.01079828527132897, 'max_depth': 5}. Best is trial 20 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:18,107] Trial 26 finished with value: 0.7884622623753058 and parameters: {'n_estimators': 142, 'learning_rate': 0.016371014922999236, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:19,171] Trial 27 finished with value: 0.7797571993224167 and parameters: {'n_estimators': 139, 'learning_rate': 0.04190560905183891, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:20,522] Trial 28 finished with value: 0.7813194052324487 and parameters: {'n_estimators': 122, 'learning_rate': 0.01346119969784883, 'max_depth': 5}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:21,416] Trial 29 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 164, 'learning_rate': 0.028777379167268687, 'max_depth': 3}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:22,124] Trial 30 finished with value: 0.784490871447393 and parameters: {'n_estimators': 139, 'learning_rate': 0.023332944085289825, 'max_depth': 3}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:23,196] Trial 31 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 146, 'learning_rate': 0.01569841718629103, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:24,302] Trial 32 finished with value: 0.7860907208733294 and parameters: {'n_estimators': 160, 'learning_rate': 0.017016022045127657, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:25,775] Trial 33 finished with value: 0.7773605621431707 and parameters: {'n_estimators': 160, 'learning_rate': 0.013790022017243777, 'max_depth': 5}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:26,972] Trial 34 finished with value: 0.7765920070267895 and parameters: {'n_estimators': 177, 'learning_rate': 0.04001098210256121, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:28,179] Trial 35 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 164, 'learning_rate': 0.012833475106419228, 'max_depth': 4}. Best is trial 26 with value: 0.7884622623753058.\n",
      "[I 2024-12-02 18:20:29,158] Trial 36 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 193, 'learning_rate': 0.012138940575596743, 'max_depth': 3}. Best is trial 36 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 18:20:30,154] Trial 37 finished with value: 0.7876623376623376 and parameters: {'n_estimators': 198, 'learning_rate': 0.012446417357065831, 'max_depth': 3}. Best is trial 36 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 18:20:31,231] Trial 38 finished with value: 0.788459125415647 and parameters: {'n_estimators': 200, 'learning_rate': 0.010091814643916182, 'max_depth': 3}. Best is trial 36 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 18:20:32,240] Trial 39 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 199, 'learning_rate': 0.010222901056389082, 'max_depth': 3}. Best is trial 36 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 18:20:33,235] Trial 40 finished with value: 0.7892496392496392 and parameters: {'n_estimators': 187, 'learning_rate': 0.010931296112857683, 'max_depth': 3}. Best is trial 36 with value: 0.7892527762092978.\n",
      "[I 2024-12-02 18:20:34,221] Trial 41 finished with value: 0.7900401530836312 and parameters: {'n_estimators': 189, 'learning_rate': 0.011286764578884443, 'max_depth': 3}. Best is trial 41 with value: 0.7900401530836312.\n",
      "[I 2024-12-02 18:20:35,185] Trial 42 finished with value: 0.7876654746219962 and parameters: {'n_estimators': 189, 'learning_rate': 0.012298169152753426, 'max_depth': 3}. Best is trial 41 with value: 0.7900401530836312.\n",
      "[I 2024-12-02 18:20:36,263] Trial 43 finished with value: 0.7821099190664407 and parameters: {'n_estimators': 187, 'learning_rate': 0.022978822774203222, 'max_depth': 3}. Best is trial 41 with value: 0.7900401530836312.\n",
      "[I 2024-12-02 18:20:37,313] Trial 44 finished with value: 0.7852813852813852 and parameters: {'n_estimators': 184, 'learning_rate': 0.015087417142691403, 'max_depth': 3}. Best is trial 41 with value: 0.7900401530836312.\n",
      "[I 2024-12-02 18:20:38,273] Trial 45 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 173, 'learning_rate': 0.01008063472570232, 'max_depth': 3}. Best is trial 45 with value: 0.7932147562582343.\n",
      "[I 2024-12-02 18:20:39,363] Trial 46 finished with value: 0.7940084070518851 and parameters: {'n_estimators': 180, 'learning_rate': 0.01010063630689374, 'max_depth': 3}. Best is trial 46 with value: 0.7940084070518851.\n",
      "[I 2024-12-02 18:20:40,001] Trial 47 finished with value: 0.786887508626639 and parameters: {'n_estimators': 176, 'learning_rate': 0.02557922574764806, 'max_depth': 2}. Best is trial 46 with value: 0.7940084070518851.\n",
      "[I 2024-12-02 18:20:40,873] Trial 48 finished with value: 0.79004329004329 and parameters: {'n_estimators': 172, 'learning_rate': 0.012844654410508747, 'max_depth': 3}. Best is trial 46 with value: 0.7940084070518851.\n",
      "[I 2024-12-02 18:20:41,779] Trial 49 finished with value: 0.7353817679904636 and parameters: {'n_estimators': 172, 'learning_rate': 0.8758730820061209, 'max_depth': 3}. Best is trial 46 with value: 0.7940084070518851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "Added 18 new labeled samples.\n",
      "--- Iteration 2 ---\n",
      "Added 5 new labeled samples.\n",
      "--- Iteration 3 ---\n",
      "Added 1 new labeled samples.\n",
      "--- Iteration 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:20:42,800] A new study created in memory with name: no-name-3e22f3fe-7813-42b5-b66f-7d5734f2b2a5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more confident predictions; stopping training.\n",
      "Accuracy on test set of co-training with Gradient Boosting with a split ratio of 40%/60%: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 18:20:43,487] Trial 0 finished with value: 0.78529393312002 and parameters: {'n_estimators': 92, 'learning_rate': 0.019131189489579363, 'max_depth': 4}. Best is trial 0 with value: 0.78529393312002.\n",
      "[I 2024-12-02 18:20:44,039] Trial 1 finished with value: 0.7773731099818055 and parameters: {'n_estimators': 59, 'learning_rate': 0.08992546389672192, 'max_depth': 5}. Best is trial 0 with value: 0.78529393312002.\n",
      "[I 2024-12-02 18:20:44,288] Trial 2 finished with value: 0.785303343998996 and parameters: {'n_estimators': 66, 'learning_rate': 0.10724386094561779, 'max_depth': 2}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:45,277] Trial 3 finished with value: 0.7543886065625196 and parameters: {'n_estimators': 191, 'learning_rate': 0.1675617299861504, 'max_depth': 3}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:47,238] Trial 4 finished with value: 0.7528107158541941 and parameters: {'n_estimators': 170, 'learning_rate': 0.10928279668167176, 'max_depth': 5}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:47,969] Trial 5 finished with value: 0.7551916682351465 and parameters: {'n_estimators': 80, 'learning_rate': 0.48160030929899833, 'max_depth': 5}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:48,449] Trial 6 finished with value: 0.7789572746094485 and parameters: {'n_estimators': 52, 'learning_rate': 0.03610897152727023, 'max_depth': 5}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:49,054] Trial 7 finished with value: 0.7821161929857581 and parameters: {'n_estimators': 121, 'learning_rate': 0.025899494032613123, 'max_depth': 3}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:49,420] Trial 8 finished with value: 0.7781636238157977 and parameters: {'n_estimators': 104, 'learning_rate': 0.11351637041290528, 'max_depth': 2}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:51,035] Trial 9 finished with value: 0.7797477884434405 and parameters: {'n_estimators': 177, 'learning_rate': 0.011208008936277523, 'max_depth': 5}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:51,339] Trial 10 finished with value: 0.76309053265575 and parameters: {'n_estimators': 136, 'learning_rate': 0.6416374594518454, 'max_depth': 1}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:51,645] Trial 11 finished with value: 0.7837129054520359 and parameters: {'n_estimators': 84, 'learning_rate': 0.040344081354715434, 'max_depth': 2}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:52,268] Trial 12 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 90, 'learning_rate': 0.01128347912658561, 'max_depth': 4}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:52,521] Trial 13 finished with value: 0.7686429512516468 and parameters: {'n_estimators': 69, 'learning_rate': 0.278281924027296, 'max_depth': 2}. Best is trial 2 with value: 0.785303343998996.\n",
      "[I 2024-12-02 18:20:53,293] Trial 14 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 109, 'learning_rate': 0.02159575902420847, 'max_depth': 4}. Best is trial 14 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:53,718] Trial 15 finished with value: 0.7789510006901311 and parameters: {'n_estimators': 142, 'learning_rate': 0.06976101761938312, 'max_depth': 1}. Best is trial 14 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:54,989] Trial 16 finished with value: 0.7726143421795595 and parameters: {'n_estimators': 118, 'learning_rate': 0.052561418356558635, 'max_depth': 4}. Best is trial 14 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:55,814] Trial 17 finished with value: 0.7599316142794403 and parameters: {'n_estimators': 149, 'learning_rate': 0.23009924575993562, 'max_depth': 3}. Best is trial 14 with value: 0.7868780977476628.\n",
      "[I 2024-12-02 18:20:56,202] Trial 18 finished with value: 0.787668611581655 and parameters: {'n_estimators': 105, 'learning_rate': 0.020059506158817558, 'max_depth': 2}. Best is trial 18 with value: 0.787668611581655.\n",
      "[I 2024-12-02 18:20:56,752] Trial 19 finished with value: 0.7900464270029486 and parameters: {'n_estimators': 107, 'learning_rate': 0.01924087910412393, 'max_depth': 3}. Best is trial 19 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:20:56,993] Trial 20 finished with value: 0.7710239036325992 and parameters: {'n_estimators': 102, 'learning_rate': 0.015349925403039264, 'max_depth': 1}. Best is trial 19 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:20:57,711] Trial 21 finished with value: 0.7868812347073216 and parameters: {'n_estimators': 104, 'learning_rate': 0.025625563242319127, 'max_depth': 4}. Best is trial 19 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:20:58,340] Trial 22 finished with value: 0.7829067068197503 and parameters: {'n_estimators': 125, 'learning_rate': 0.03074301780296434, 'max_depth': 3}. Best is trial 19 with value: 0.7900464270029486.\n",
      "[I 2024-12-02 18:20:58,998] Trial 23 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 131, 'learning_rate': 0.014525125966673186, 'max_depth': 3}. Best is trial 23 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:20:59,757] Trial 24 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 150, 'learning_rate': 0.014861140438426665, 'max_depth': 3}. Best is trial 23 with value: 0.7908369408369408.\n",
      "[I 2024-12-02 18:21:00,580] Trial 25 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 163, 'learning_rate': 0.013449574826237626, 'max_depth': 3}. Best is trial 25 with value: 0.7916274546709328.\n",
      "[I 2024-12-02 18:21:01,354] Trial 26 finished with value: 0.7932147562582345 and parameters: {'n_estimators': 153, 'learning_rate': 0.010016577823053078, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:02,146] Trial 27 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 157, 'learning_rate': 0.010816138135311806, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:02,977] Trial 28 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 164, 'learning_rate': 0.010056393131436416, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:04,273] Trial 29 finished with value: 0.7900464270029486 and parameters: {'n_estimators': 189, 'learning_rate': 0.010474067346101033, 'max_depth': 4}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:04,838] Trial 30 finished with value: 0.7900558378819248 and parameters: {'n_estimators': 159, 'learning_rate': 0.04269063880923978, 'max_depth': 2}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:05,679] Trial 31 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 167, 'learning_rate': 0.01034262249326868, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:07,095] Trial 32 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 181, 'learning_rate': 0.018106049904962195, 'max_depth': 4}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:07,909] Trial 33 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 158, 'learning_rate': 0.010255560667971935, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:08,914] Trial 34 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 199, 'learning_rate': 0.013181952115652262, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:09,824] Trial 35 finished with value: 0.7797383775644645 and parameters: {'n_estimators': 169, 'learning_rate': 0.02564542516687149, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:10,355] Trial 36 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 146, 'learning_rate': 0.017241079852076912, 'max_depth': 2}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:11,539] Trial 37 finished with value: 0.7686743208482338 and parameters: {'n_estimators': 177, 'learning_rate': 0.060475511388878016, 'max_depth': 4}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:12,137] Trial 38 finished with value: 0.787668611581655 and parameters: {'n_estimators': 167, 'learning_rate': 0.012486078117209391, 'max_depth': 2}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:12,925] Trial 39 finished with value: 0.7821193299454169 and parameters: {'n_estimators': 154, 'learning_rate': 0.030702871907501393, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:13,862] Trial 40 finished with value: 0.7908369408369408 and parameters: {'n_estimators': 185, 'learning_rate': 0.010055381027288146, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:14,713] Trial 41 finished with value: 0.7876654746219962 and parameters: {'n_estimators': 163, 'learning_rate': 0.014525049085540946, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:15,598] Trial 42 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 174, 'learning_rate': 0.013039873275428287, 'max_depth': 3}. Best is trial 26 with value: 0.7932147562582345.\n",
      "[I 2024-12-02 18:21:16,438] Trial 43 finished with value: 0.7940084070518852 and parameters: {'n_estimators': 163, 'learning_rate': 0.010062936999361716, 'max_depth': 3}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:17,243] Trial 44 finished with value: 0.7829035698600915 and parameters: {'n_estimators': 140, 'learning_rate': 0.0222481954671092, 'max_depth': 3}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:17,842] Trial 45 finished with value: 0.7837066315327185 and parameters: {'n_estimators': 156, 'learning_rate': 0.016909319885894745, 'max_depth': 2}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:19,362] Trial 46 finished with value: 0.7377501725327813 and parameters: {'n_estimators': 196, 'learning_rate': 0.9216517789522961, 'max_depth': 4}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:20,163] Trial 47 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 133, 'learning_rate': 0.011859315272386674, 'max_depth': 3}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:21,531] Trial 48 finished with value: 0.7829192546583851 and parameters: {'n_estimators': 168, 'learning_rate': 0.010225723447182295, 'max_depth': 4}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:22,160] Trial 49 finished with value: 0.7765700483091788 and parameters: {'n_estimators': 174, 'learning_rate': 0.13296845722722794, 'max_depth': 2}. Best is trial 43 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:22,161] A new study created in memory with name: no-name-864d5ff7-2840-45cd-a3ea-23dd9cc3fcd5\n",
      "[I 2024-12-02 18:21:22,832] Trial 0 finished with value: 0.7805257544387979 and parameters: {'n_estimators': 192, 'learning_rate': 0.07139889927955866, 'max_depth': 2}. Best is trial 0 with value: 0.7805257544387979.\n",
      "[I 2024-12-02 18:21:24,283] Trial 1 finished with value: 0.758363134450091 and parameters: {'n_estimators': 150, 'learning_rate': 0.06640674596846738, 'max_depth': 5}. Best is trial 0 with value: 0.7805257544387979.\n",
      "[I 2024-12-02 18:21:25,002] Trial 2 finished with value: 0.79004329004329 and parameters: {'n_estimators': 131, 'learning_rate': 0.016167567276418087, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:25,267] Trial 3 finished with value: 0.7528169897735115 and parameters: {'n_estimators': 52, 'learning_rate': 0.646024941307608, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:25,532] Trial 4 finished with value: 0.7638810464897421 and parameters: {'n_estimators': 104, 'learning_rate': 0.6967121417006363, 'max_depth': 1}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:25,710] Trial 5 finished with value: 0.7599253403601229 and parameters: {'n_estimators': 72, 'learning_rate': 0.9013081414744639, 'max_depth': 1}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:26,841] Trial 6 finished with value: 0.7726174791392182 and parameters: {'n_estimators': 159, 'learning_rate': 0.047913665539223396, 'max_depth': 4}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:27,078] Trial 7 finished with value: 0.7837160424116946 and parameters: {'n_estimators': 61, 'learning_rate': 0.05853252630103231, 'max_depth': 2}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:28,881] Trial 8 finished with value: 0.7757889453541628 and parameters: {'n_estimators': 199, 'learning_rate': 0.019543269190441193, 'max_depth': 5}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:29,840] Trial 9 finished with value: 0.7646997929606625 and parameters: {'n_estimators': 136, 'learning_rate': 0.1384593101321626, 'max_depth': 4}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:30,379] Trial 10 finished with value: 0.7844971453667104 and parameters: {'n_estimators': 101, 'learning_rate': 0.011222861632746398, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:30,982] Trial 11 finished with value: 0.7852907961603612 and parameters: {'n_estimators': 118, 'learning_rate': 0.010158224841775691, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:31,409] Trial 12 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 111, 'learning_rate': 0.010198737757240112, 'max_depth': 2}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:32,298] Trial 13 finished with value: 0.7813288161114247 and parameters: {'n_estimators': 128, 'learning_rate': 0.024991090359825486, 'max_depth': 4}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:32,728] Trial 14 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 83, 'learning_rate': 0.023684389172380447, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:33,309] Trial 15 finished with value: 0.787668611581655 and parameters: {'n_estimators': 84, 'learning_rate': 0.02856542685276927, 'max_depth': 4}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:33,632] Trial 16 finished with value: 0.7773448773448772 and parameters: {'n_estimators': 89, 'learning_rate': 0.12802217511207012, 'max_depth': 2}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:34,444] Trial 17 finished with value: 0.7551822573561704 and parameters: {'n_estimators': 162, 'learning_rate': 0.23505910979894137, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:35,138] Trial 18 finished with value: 0.7821161929857581 and parameters: {'n_estimators': 137, 'learning_rate': 0.034246718881403876, 'max_depth': 3}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:35,765] Trial 19 finished with value: 0.7765669113495199 and parameters: {'n_estimators': 177, 'learning_rate': 0.27372880659257576, 'max_depth': 2}. Best is trial 2 with value: 0.79004329004329.\n",
      "[I 2024-12-02 18:21:36,374] Trial 20 finished with value: 0.7900495639626075 and parameters: {'n_estimators': 88, 'learning_rate': 0.01870142409625125, 'max_depth': 4}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:36,995] Trial 21 finished with value: 0.7868780977476628 and parameters: {'n_estimators': 82, 'learning_rate': 0.015943826969266536, 'max_depth': 4}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:37,625] Trial 22 finished with value: 0.7797446514837819 and parameters: {'n_estimators': 68, 'learning_rate': 0.016772801927853128, 'max_depth': 5}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:38,297] Trial 23 finished with value: 0.7829161176987263 and parameters: {'n_estimators': 98, 'learning_rate': 0.034209307738111004, 'max_depth': 4}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:38,919] Trial 24 finished with value: 0.7868718238283454 and parameters: {'n_estimators': 122, 'learning_rate': 0.020942048358404977, 'max_depth': 3}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:39,544] Trial 25 finished with value: 0.7821256038647343 and parameters: {'n_estimators': 91, 'learning_rate': 0.04362777165696773, 'max_depth': 4}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:39,934] Trial 26 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 75, 'learning_rate': 0.01688830719479499, 'max_depth': 3}. Best is trial 20 with value: 0.7900495639626075.\n",
      "[I 2024-12-02 18:21:40,498] Trial 27 finished with value: 0.7940084070518852 and parameters: {'n_estimators': 110, 'learning_rate': 0.013686257216967035, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:41,801] Trial 28 finished with value: 0.7805351653177739 and parameters: {'n_estimators': 142, 'learning_rate': 0.013157893427609214, 'max_depth': 5}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:42,198] Trial 29 finished with value: 0.7868843716669803 and parameters: {'n_estimators': 107, 'learning_rate': 0.03734678718791099, 'max_depth': 2}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:43,010] Trial 30 finished with value: 0.7742267394441307 and parameters: {'n_estimators': 115, 'learning_rate': 0.09142303174679897, 'max_depth': 4}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:43,500] Trial 31 finished with value: 0.7868718238283454 and parameters: {'n_estimators': 95, 'learning_rate': 0.025751430920216464, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:44,148] Trial 32 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 127, 'learning_rate': 0.013634836965018823, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:44,791] Trial 33 finished with value: 0.7940084070518851 and parameters: {'n_estimators': 126, 'learning_rate': 0.01419584051835444, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:45,569] Trial 34 finished with value: 0.7892527762092978 and parameters: {'n_estimators': 147, 'learning_rate': 0.013392444889112681, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:46,232] Trial 35 finished with value: 0.7932147562582343 and parameters: {'n_estimators': 125, 'learning_rate': 0.013983618667715084, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:46,797] Trial 36 finished with value: 0.7860813099943534 and parameters: {'n_estimators': 155, 'learning_rate': 0.013869344456993395, 'max_depth': 2}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:47,621] Trial 37 finished with value: 0.7924211054645836 and parameters: {'n_estimators': 127, 'learning_rate': 0.013550589070761301, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:48,009] Trial 38 finished with value: 0.7797477884434405 and parameters: {'n_estimators': 168, 'learning_rate': 0.05680031460806104, 'max_depth': 1}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:48,711] Trial 39 finished with value: 0.7472677081372734 and parameters: {'n_estimators': 133, 'learning_rate': 0.3745913877231662, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:49,162] Trial 40 finished with value: 0.7805351653177739 and parameters: {'n_estimators': 121, 'learning_rate': 0.07046223841139437, 'max_depth': 2}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:49,814] Trial 41 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 127, 'learning_rate': 0.012685911897135521, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:50,402] Trial 42 finished with value: 0.7916274546709328 and parameters: {'n_estimators': 111, 'learning_rate': 0.014908679497013251, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:51,125] Trial 43 finished with value: 0.7860718991153772 and parameters: {'n_estimators': 141, 'learning_rate': 0.020596356980803216, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:51,764] Trial 44 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 125, 'learning_rate': 0.010142398937485284, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:52,156] Trial 45 finished with value: 0.7844940084070519 and parameters: {'n_estimators': 104, 'learning_rate': 0.011984496318935358, 'max_depth': 2}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:52,742] Trial 46 finished with value: 0.784490871447393 and parameters: {'n_estimators': 116, 'learning_rate': 0.03018151647014583, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:53,493] Trial 47 finished with value: 0.784490871447393 and parameters: {'n_estimators': 149, 'learning_rate': 0.022005935571192407, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:54,388] Trial 48 finished with value: 0.786084446954012 and parameters: {'n_estimators': 132, 'learning_rate': 0.017925673092219607, 'max_depth': 4}. Best is trial 27 with value: 0.7940084070518852.\n",
      "[I 2024-12-02 18:21:54,944] Trial 49 finished with value: 0.7884559884559884 and parameters: {'n_estimators': 110, 'learning_rate': 0.01202434815595192, 'max_depth': 3}. Best is trial 27 with value: 0.7940084070518852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n",
      "No more confident predictions; stopping training.\n",
      "Accuracy on test set of co-training with Gradient Boosting with a split ratio of 50%/50%: 0.7480\n"
     ]
    }
   ],
   "source": [
    "split_ratios = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    np.random.seed(42) # for reproducibility\n",
    "\n",
    "    # calculate the number of labeled samples required\n",
    "    num_labeled = int(split_ratio * num_samples)\n",
    "    labeled_indices = np.random.choice(num_samples, num_labeled, replace=False)\n",
    "    \n",
    "    # sampling from the training set (rows with -1 are unlabeled, others are labeled)\n",
    "    y_mushroom_train_unlabeled = np.full_like(y_mushroom_train, fill_value=-1)\n",
    "    y_mushroom_train_unlabeled[labeled_indices] = y_mushroom_train[labeled_indices]\n",
    "\n",
    "    labeled_indices = np.where(y_mushroom_train_unlabeled != -1)[0]\n",
    "    unlabeled_indices = np.where(y_mushroom_train_unlabeled == -1)[0]\n",
    "    X_labeled = X_mushroom_train.iloc[labeled_indices]\n",
    "    y_labeled = y_mushroom_train_unlabeled[labeled_indices]\n",
    "    X_unlabeled = X_mushroom_train.iloc[unlabeled_indices]\n",
    "\n",
    "    # train each ssl algorithm and evaluate\n",
    "    # self_training_gradient_boosting(y_mushroom_train_unlabeled, split_ratio)\n",
    "    co_training_gradient_boosting(X_labeled, X_unlabeled, y_labeled, split_ratio)\n",
    "    # semi_supervised_ensemble(X_labeled, X_unlabeled, y_labeled, split_ratio)\n",
    "    # unsupervised_pretraining(X_labeled, X_unlabeled, y_labeled, split_ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "# accuracy\n",
    "# precision\n",
    "# recall\n",
    "# f1-score\n",
    "# AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
